{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarzamHejaziK/BasicML/blob/main/nb/Qwen3_(4B)-GRPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Hb6Dvoi2VM"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I4w4OUE9lvo"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "furZbyFy9lvq"
      },
      "source": [
        "Read our **[Qwen3 Guide](https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt29NJfP9lvs"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AgKwzU9L9lvs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "IWoEsnCOf3uc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install vllm"
      ],
      "metadata": {
        "id": "Wfb_EvNJexhy",
        "outputId": "dbb9418f-af31-4a2a-e0e6-1313b35e550f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.8.5.post1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.51.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm) (0.31.2)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (5.29.4)\n",
            "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.78.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.4)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.9 (from vllm)\n",
            "  Downloading llguidance-0.7.24-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.18 (from vllm)\n",
            "  Downloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.13.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting pyzmq>=25.0.0 (from vllm)\n",
            "  Downloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.7.0)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm)\n",
            "  Downloading mistral_common-1.5.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.9.3 (from vllm)\n",
            "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-json-logger (from vllm)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm)\n",
            "  Downloading opentelemetry_semantic_conventions_ai-0.4.9-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
            "  Downloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0+cu124)\n",
            "Collecting xformers==0.0.29.post2 (from vllm)\n",
            "  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.3.7)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20250523-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm) (1.3.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (24.2)\n",
            "Collecting hf-xet<2.0.0,>=1.1.1 (from huggingface-hub[hf_xet]>=0.30.0->vllm)\n",
            "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting importlib_metadata (from vllm)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from vllm)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.4.26)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.1->vllm) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.3)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.14.6-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading compressed_tensors-0.9.3-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.16.3-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.4/94.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.24-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.6-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m133.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions_ai-0.4.9-py3-none-any.whl (5.6 kB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.4/862.4 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl (68.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.5/385.5 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading airportsdata-20250523-py3-none-any.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich_toolkit-0.14.6-py3-none-any.whl (24 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blake3, uvloop, uvicorn, pyzmq, python-multipart, python-json-logger, python-dotenv, pycountry, protobuf, partial-json-parser, opentelemetry-semantic-conventions-ai, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, msgspec, llvmlite, llguidance, lark, interegular, importlib_metadata, httptools, hf-xet, gguf, dnspython, diskcache, deprecated, astor, airportsdata, watchfiles, starlette, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, email-validator, depyf, rich-toolkit, prometheus-fastapi-instrumentator, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, nvidia-cusolver-cu12, lm-format-enforcer, fastapi, ray, outlines_core, opentelemetry-sdk, mistral_common, fastapi-cli, xgrammar, xformers, outlines, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, compressed-tensors, opentelemetry-exporter-otlp\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 24.0.1\n",
            "    Uninstalling pyzmq-24.0.1:\n",
            "      Successfully uninstalled pyzmq-24.0.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth 2025.5.7 requires bitsandbytes, which is not installed.\n",
            "unsloth 2025.5.7 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9, which is not installed.\n",
            "unsloth 2025.5.7 requires tyro, which is not installed.\n",
            "unsloth 2025.5.7 requires unsloth_zoo>=2025.5.8, which is not installed.\n",
            "unsloth 2025.5.7 requires datasets>=3.4.1, but you have datasets 2.14.4 which is incompatible.\n",
            "unsloth 2025.5.7 requires protobuf<4.0.0, but you have protobuf 4.25.7 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed airportsdata-20250523 astor-0.8.1 blake3-1.0.5 compressed-tensors-0.9.3 deprecated-1.2.18 depyf-0.18.0 diskcache-5.6.3 dnspython-2.7.0 email-validator-2.2.0 fastapi-0.115.12 fastapi-cli-0.0.7 gguf-0.16.3 hf-xet-1.1.2 httptools-0.6.4 importlib_metadata-8.0.0 interegular-0.3.3 lark-1.2.2 llguidance-0.7.24 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.5.6 msgspec-0.19.0 ninja-1.11.1.4 numba-0.61.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-semantic-conventions-ai-0.4.9 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.1.0 protobuf-4.25.7 pycountry-24.6.1 python-dotenv-1.1.0 python-json-logger-3.3.0 python-multipart-0.0.20 pyzmq-26.4.0 ray-2.46.0 rich-toolkit-0.14.6 starlette-0.46.2 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 xformers-0.0.29.post2 xgrammar-0.1.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "5980a1c52c964ba4b0d8c2082293c033"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jZhY2Dm9lvt"
      },
      "outputs": [],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkH_y8UC9lvv"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN75nmdx9lvw"
      },
      "source": [
        "Goal: To convert `Qwen3-4B-Base` into a reasoning model via GRPO by using OpenR1's Math dataset.\n",
        "\n",
        "We first pre fine-tune the model to make GRPO skip trying to match formatting - this speeds GRPO up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "2a2d0451-0230-4a4f-d833-8a14d3799221"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bitsandbytes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8d47ba451086>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m \u001b[0;31m# Can increase for longer reasoning traces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlora_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;31m# Larger rank = smarter, but slower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Try loading bitsandbytes and triton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mbitsandbytes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mcdequantize_blockwise_fp32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdequantize_blockwise_fp32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bitsandbytes'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Can increase for longer reasoning traces\n",
        "lora_rank = 32 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen3-4B-Base\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = False, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.7, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
        "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9DuiVRLhMco"
      },
      "source": [
        "### GRPO chat template\n",
        "Since we're using a base model, we should set a chat template. You can make your own chat template as well!\n",
        "1. DeepSeek uses `<think>` and `</think>`, but this is **not** necessary - you can customize it however you like!\n",
        "2. A `system_prompt` is recommended to at least guide the model's responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UjowCbT-cFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "71bd035e-6cc1-4c1f-979d-e52a700fd913"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "reasoning_start = \"<start_working_out>\" # Acts as <think>\n",
        "reasoning_end   = \"<end_working_out>\"   # Acts as </think>\n",
        "solution_start  = \"<SOLUTION>\"\n",
        "solution_end    = \"</SOLUTION>\"\n",
        "\n",
        "system_prompt = \\\n",
        "f\"\"\"You are given a problem.\n",
        "Think about the problem and provide your working out.\n",
        "Place it between {reasoning_start} and {reasoning_end}.\n",
        "Then, provide your solution between {solution_start}{solution_end}\"\"\"\n",
        "system_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a simple chat template below. Notice `add_generation_prompt` includes prepending `<start_working_out>` to guide the model to start its reasoning process."
      ],
      "metadata": {
        "id": "zGgs0MJkDkYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = \\\n",
        "    \"{% if messages[0]['role'] == 'system' %}\"\\\n",
        "        \"{{ messages[0]['content'] + eos_token }}\"\\\n",
        "        \"{% set loop_messages = messages[1:] %}\"\\\n",
        "    \"{% else %}\"\\\n",
        "        \"{{ '{system_prompt}' + eos_token }}\"\\\n",
        "        \"{% set loop_messages = messages %}\"\\\n",
        "    \"{% endif %}\"\\\n",
        "    \"{% for message in loop_messages %}\"\\\n",
        "        \"{% if message['role'] == 'user' %}\"\\\n",
        "            \"{{ message['content'] }}\"\\\n",
        "        \"{% elif message['role'] == 'assistant' %}\"\\\n",
        "            \"{{ message['content'] + eos_token }}\"\\\n",
        "        \"{% endif %}\"\\\n",
        "    \"{% endfor %}\"\\\n",
        "    \"{% if add_generation_prompt %}{{ '{reasoning_start}' }}\"\\\n",
        "    \"{% endif %}\"\n",
        "\n",
        "# Replace with out specific template:\n",
        "chat_template = chat_template\\\n",
        "    .replace(\"'{system_prompt}'\",   f\"'{system_prompt}'\")\\\n",
        "    .replace(\"'{reasoning_start}'\", f\"'{reasoning_start}'\")\n",
        "tokenizer.chat_template = chat_template"
      ],
      "metadata": {
        "id": "Y3fF9gMujY02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how our chat template behaves on an example:"
      ],
      "metadata": {
        "id": "vEcLdymBEHdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"What is 1+1?\"},\n",
        "    {\"role\" : \"assistant\", \"content\" : f\"{reasoning_start}I think it's 2.{reasoning_end}{solution_start}2{solution_end}\"},\n",
        "    {\"role\" : \"user\", \"content\" : \"What is 2+2?\"},\n",
        "], tokenize = False, add_generation_prompt = True)"
      ],
      "metadata": {
        "id": "BciEDYSSYFNj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0d5669d2-6e42-4c2f-d751-8a72f72b45e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION><|endoftext|>What is 1+1?<start_working_out>I think it's 2.<end_working_out><SOLUTION>2</SOLUTION><|endoftext|>What is 2+2?<start_working_out>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre fine-tuning for formatting\n",
        "We now use a subset of NVIDIA's [Open Math Reasoning dataset](https://huggingface.co/datasets/nvidia/OpenMathReasoning) which was filtered to only include high quality DeepSeek R1 traces.\n",
        "\n",
        "We'll only filter ~59 or so examples to first \"prime\" / pre fine-tune the model to understand our custom GRPO formatting."
      ],
      "metadata": {
        "id": "_mdsuGjxHrjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = load_dataset(\"unsloth/OpenMathReasoning-mini\", split = \"cot\")\n",
        "dataset = dataset.to_pandas()[\n",
        "    [\"expected_answer\", \"problem\", \"generated_solution\"]\n",
        "]\n",
        "\n",
        "# Try converting to number - if not, replace with NaN\n",
        "is_number = pd.to_numeric(pd.Series(dataset[\"expected_answer\"]), errors = \"coerce\").notnull()\n",
        "# Select only numbers\n",
        "dataset = dataset.iloc[np.where(is_number)[0]]\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "AXxM2lStVIkd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "185b0c62-183a-4333-90d3-1af44e9376b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      expected_answer                                            problem  \\\n",
              "0                  14  Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...   \n",
              "6                  -2  Find the value of the parameter $a$ for which ...   \n",
              "9                  18  What is the sum of all real numbers $x$ for wh...   \n",
              "13                  2  Evaluate the sum \\(\\sum_{n=1}^\\infty \\frac{\\ph...   \n",
              "17                 30  What is the largest positive integer that divi...   \n",
              "...               ...                                                ...   \n",
              "19243             244  Let \\( p \\), \\( q \\), and \\( r \\) be the disti...   \n",
              "19245               1  A bug is on the $0$ of a number line. At any p...   \n",
              "19247               4  A bus left point X for point Y. Two hours late...   \n",
              "19248              18  Each interior angle of a regular n-gon measure...   \n",
              "19250          0.8960  Find the probability that the second blue resu...   \n",
              "\n",
              "                                      generated_solution  \n",
              "0      <think>\\nOkay, let's see. I need to solve the ...  \n",
              "6      <think>\\nOkay, so I need to find the value of ...  \n",
              "9      <think>\\nOkay, so I need to solve the equation...  \n",
              "13     <think>\\nOkay, so I need to evaluate the infin...  \n",
              "17     <think>\\nAlright, so I need to find the larges...  \n",
              "...                                                  ...  \n",
              "19243  <think>\\nOkay, so I need to find the value of ...  \n",
              "19245  <think>\\nOkay, so I have this problem where a ...  \n",
              "19247  <think>\\nOkay, let's tackle this problem step ...  \n",
              "19248  <think>\\nOkay, let's see. I need to find the n...  \n",
              "19250  <think>\\nOkay, so I need to find the probabili...  \n",
              "\n",
              "[7507 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-112a41c3-35a5-411f-9c1a-f86df8b6f2bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>expected_answer</th>\n",
              "      <th>problem</th>\n",
              "      <th>generated_solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's see. I need to solve the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-2</td>\n",
              "      <td>Find the value of the parameter $a$ for which ...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to find the value of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>18</td>\n",
              "      <td>What is the sum of all real numbers $x$ for wh...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to solve the equation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>Evaluate the sum \\(\\sum_{n=1}^\\infty \\frac{\\ph...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to evaluate the infin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>30</td>\n",
              "      <td>What is the largest positive integer that divi...</td>\n",
              "      <td>&lt;think&gt;\\nAlright, so I need to find the larges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19243</th>\n",
              "      <td>244</td>\n",
              "      <td>Let \\( p \\), \\( q \\), and \\( r \\) be the disti...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to find the value of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19245</th>\n",
              "      <td>1</td>\n",
              "      <td>A bug is on the $0$ of a number line. At any p...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I have this problem where a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19247</th>\n",
              "      <td>4</td>\n",
              "      <td>A bus left point X for point Y. Two hours late...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's tackle this problem step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19248</th>\n",
              "      <td>18</td>\n",
              "      <td>Each interior angle of a regular n-gon measure...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's see. I need to find the n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19250</th>\n",
              "      <td>0.8960</td>\n",
              "      <td>Find the probability that the second blue resu...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to find the probabili...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7507 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-112a41c3-35a5-411f-9c1a-f86df8b6f2bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-112a41c3-35a5-411f-9c1a-f86df8b6f2bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-112a41c3-35a5-411f-9c1a-f86df8b6f2bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b70ce49-483b-4539-b5cd-ac29c0563e2f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b70ce49-483b-4539-b5cd-ac29c0563e2f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b70ce49-483b-4539-b5cd-ac29c0563e2f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3373297d-8b78-41a2-ab91-94be6ad04813\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3373297d-8b78-41a2-ab91-94be6ad04813 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 7507,\n  \"fields\": [\n    {\n      \"column\": \"expected_answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 868,\n        \"samples\": [\n          \"672\",\n          \"335\",\n          \"575757\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"problem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3895,\n        \"samples\": [\n          \"A club with 7 members forms three-person committees, but no two committees can have more than one member in common. What is the maximum number of committees that can be formed?\",\n          \"Find the smallest integer \\\\( a > 2 \\\\) such that \\\\( 2 \\\\mid a \\\\), \\\\( 3 \\\\mid (a+1) \\\\), \\\\( 4 \\\\mid (a+2) \\\\), \\\\( 5 \\\\mid (a+3) \\\\), and \\\\( 6 \\\\mid (a+4) \\\\).\",\n          \"Given the polynomial equation \\\\(x^3 - x = -1\\\\) with roots \\\\(a\\\\), \\\\(b\\\\), and \\\\(c\\\\), find the value of \\\\(\\\\frac{1}{1+a} + \\\\frac{1}{1+b} + \\\\frac{1}{1+c}\\\\).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_solution\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7507,\n        \"samples\": [\n          \"<think>\\nOkay, let's see. I need to solve this problem where there are three prime numbers p, q, and r. The equations given are pq + qr + rp = 191 and p + q = r - 1. The goal is to find p + q + r. Hmm, primes, so they must be 2 or odd primes. Let me start by analyzing the problem step by step.\\n\\nFirst, the equation p + q = r - 1. If I can express r in terms of p and q, maybe I can substitute that into the first equation. Let's try that. So, from the second equation, r = p + q + 1. That seems straightforward. Now, substituting this into the first equation, we get pq + qr + rp = 191. Let's replace r with (p + q + 1).\\n\\nSo, substituting, the first equation becomes:\\n\\npq + q(p + q + 1) + p(p + q + 1) = 191.\\n\\nLet me expand each term:\\n\\nFirst term: pq.\\n\\nSecond term: q*(p + q + 1) = pq + q\\u00b2 + q.\\n\\nThird term: p*(p + q + 1) = p\\u00b2 + pq + p.\\n\\nNow, adding all these together:\\n\\npq + (pq + q\\u00b2 + q) + (p\\u00b2 + pq + p) = 191.\\n\\nCombine like terms:\\n\\npq + pq + pq = 3pq.\\n\\nq\\u00b2 + p\\u00b2.\\n\\nq + p.\\n\\nSo altogether, the equation becomes:\\n\\np\\u00b2 + q\\u00b2 + 3pq + p + q = 191.\\n\\nHmm. Let me note that.\\n\\nAlternatively, maybe I can factor this expression. Let me see. Let's try to group terms. Wait, another approach: since r = p + q + 1, then p + q + r = (p + q) + (p + q + 1) = 2(p + q) + 1. So if I can find p + q, then multiplying by 2 and adding 1 gives me the answer. That's useful. So perhaps instead of dealing with the first equation directly, I can express it in terms of p + q.\\n\\nBut maybe let's work with the equation we derived: p\\u00b2 + q\\u00b2 + 3pq + p + q = 191.\\n\\nWait, another thought: p\\u00b2 + q\\u00b2 + 3pq. Let's recall that (p + q)^2 = p\\u00b2 + 2pq + q\\u00b2, so p\\u00b2 + q\\u00b2 + 3pq = (p + q)^2 + pq.\\n\\nTherefore, the equation can be rewritten as:\\n\\n(p + q)^2 + pq + p + q = 191.\\n\\nLet me set S = p + q, and P = pq. Then the equation becomes:\\n\\nS\\u00b2 + P + S = 191.\\n\\nBut from the second equation, we know that r = S + 1, so since we need to find S + r = S + (S + 1) = 2S + 1. So our target is 2S + 1. So if we can find S, we can find the answer.\\n\\nNow, the equation is S\\u00b2 + P + S = 191. But S and P are related as S = p + q, P = pq. For two primes p and q, their sum and product. Since p and q are primes, maybe we can list possible primes that add up to S and multiply to P. However, since S and P are variables here, maybe we can express P in terms of S from the equation.\\n\\nFrom S\\u00b2 + P + S = 191, so P = 191 - S\\u00b2 - S.\\n\\nTherefore, P = -S\\u00b2 - S + 191. But P = pq must be positive, so -S\\u00b2 - S + 191 > 0. Therefore, S\\u00b2 + S < 191. Let's see the possible values of S. Since S is the sum of two primes, which are at least 2 each, so S is at least 2 + 2 = 4. Also, since S\\u00b2 + S < 191, let's solve S\\u00b2 + S - 191 < 0. Let's find the roots of S\\u00b2 + S - 191 = 0.\\n\\nUsing quadratic formula: S = [-1 \\u00b1 sqrt(1 + 4*191)] / 2 = [-1 \\u00b1 sqrt(765)] / 2. sqrt(765) is approx 27.66, so S \\u2248 (-1 + 27.66)/2 \\u2248 13.33. So the positive root is approximately 13.33, so S must be less than 13.33. Therefore, S can be integers from 4 up to 13.\\n\\nSo possible S values: 4,5,6,7,8,9,10,11,12,13.\\n\\nBut since p and q are primes, their sum S must be even or odd. Since except for 2, all primes are odd. So if both p and q are odd primes, their sum is even. If one is 2 and the other is odd, then their sum is odd. So S can be even or odd. So possible values of S (from 4 to 13) can be checked.\\n\\nBut maybe instead of all possible S, let's check possible S values from 4 to 13 and see if for each S, P = 191 - S\\u00b2 - S, and check if P can be expressed as the product of two primes that add up to S.\\n\\nAlternatively, maybe first check which S gives P as a product of two primes.\\n\\nLet's start with S=4. Then P = 191 - 16 -4 = 171. Then check if 171 can be written as product of two primes that add up to 4. But 4 is the sum. The primes could be 2 and 2 (since 2+2=4). Then 2*2=4, but P here is 171. 4 \\u2260 171, so S=4 is invalid.\\n\\nNext S=5: P=191 -25 -5=161. 161 factors into 7*23. Check if 7 + 23 = 30, which is not 5. So that's not possible. Alternatively, are there primes adding to 5? 2 and 3, since 2+3=5. Then P=2*3=6. But 6 \\u2260 161. So S=5 invalid.\\n\\nS=6: P=191 -36 -6=149. 149 is a prime number, so can't be expressed as product of two primes. So invalid.\\n\\nS=7: P=191 -49 -7=135. 135 factors into 5*27 (but 27 not prime), 3*45, 9*15, none primes. So no. So invalid.\\n\\nS=8: P=191 -64 -8=119. 119 factors into 7*17. Check if 7+17=24\\u22608. Primes adding to 8 are 3+5=8 or 5+3. Then P=15. But 15\\u2260119. So invalid.\\n\\nS=9: P=191 -81 -9=101. 101 is prime, so no.\\n\\nS=10: P=191 -100 -10=81. 81=9*9, but 9 not prime. So no.\\n\\nS=11: P=191 -121 -11=59. 59 is prime. So no.\\n\\nS=12: P=191 -144 -12=35. 35=5*7. Check if 5 +7=12? Yes! 5 +7=12. So here, S=12, which is p + q=12, and pq=35. 5 and 7 are primes. So this works.\\n\\nSo then p=5 and q=7, or p=7 and q=5. Then r = S + 1 =12 +1=13. Check if r is prime: 13 is prime. So yes. So then p, q, r are 5,7,13 or 7,5,13. Then p + q + r =5 +7 +13=25. So 25 would be the answer.\\n\\nWait, let me check S=13 as well just to be thorough. S=13: P=191 -169 -13=9. 9=3*3. Check if 3 +3=6\\u226013. So no. So no.\\n\\nTherefore, only S=12 gives valid primes. So the answer is 25.\\n\\nLet me verify the original equations. pq + qr + rp. Let p=5, q=7, r=13. Then 5*7 +7*13 +13*5 =35 +91 +65=35+91=126+65=191. Which matches. And p + q =5 +7=12. r -1=13 -1=12. So that also matches. So it's correct. Therefore, the answer is 25.\\n</think>To solve the problem where three prime numbers \\\\( p, q, \\\\) and \\\\( r \\\\) satisfy the equations \\\\( pq + qr + rp = 191 \\\\) and \\\\( p + q = r - 1 \\\\), we proceed as follows:\\n\\n1. **Express \\\\( r \\\\) in terms of \\\\( p \\\\) and \\\\( q \\\\):**\\n   From the equation \\\\( p + q = r - 1 \\\\), we can solve for \\\\( r \\\\):\\n   \\\\[\\n   r = p + q + 1\\n   \\\\]\\n\\n2. **Substitute \\\\( r \\\\) into the first equation:**\\n   Substitute \\\\( r = p + q + 1 \\\\) into the equation \\\\( pq + qr + rp = 191 \\\\):\\n   \\\\[\\n   pq + q(p + q + 1) + p(p + q + 1) = 191\\n   \\\\]\\n   Expanding and combining like terms:\\n   \\\\[\\n   pq + pq + q^2 + q + p^2 + pq + p = 191\\n   \\\\]\\n   Simplify:\\n   \\\\[\\n   p^2 + q^2 + 3pq + p + q = 191\\n   \\\\]\\n\\n3. **Introduce new variables:**\\n   Let \\\\( S = p + q \\\\) and \\\\( P = pq \\\\). The equation becomes:\\n   \\\\[\\n   S^2 + P + S = 191\\n   \\\\]\\n\\n4. **Express \\\\( r \\\\) in terms of \\\\( S \\\\):**\\n   Since \\\\( r = p + q + 1 = S + 1 \\\\), we need to find \\\\( S \\\\) such that \\\\( S^2 + P + S = 191 \\\\) and \\\\( P = pq \\\\) is the product of two primes \\\\( p \\\\) and \\\\( q \\\\) that sum to \\\\( S \\\\).\\n\\n5. **Determine possible values for \\\\( S \\\\):**\\n   Solve the inequality \\\\( S^2 + S < 191 \\\\):\\n   \\\\[\\n   S^2 + S - 191 < 0\\n   \\\\]\\n   Using the quadratic formula \\\\( S = \\\\frac{-1 \\\\pm \\\\sqrt{1 + 4 \\\\cdot 191}}{2} \\\\):\\n   \\\\[\\n   S = \\\\frac{-1 \\\\pm \\\\sqrt{765}}{2}\\n   \\\\]\\n   Since \\\\( \\\\sqrt{765} \\\\approx 27.66 \\\\), we have:\\n   \\\\[\\n   S \\\\approx \\\\frac{-1 + 27.66}{2} \\\\approx 13.33\\n   \\\\]\\n   Therefore, \\\\( S \\\\) must be an integer between 4 and 13.\\n\\n6. **Check possible values of \\\\( S \\\\):**\\n   - For \\\\( S = 12 \\\\):\\n     \\\\[\\n     P = 191 - 12^2 - 12 = 191 - 144 - 12 = 35\\n     \\\\]\\n     Check if \\\\( 35 \\\\) can be written as the product of two primes that sum to 12:\\n     \\\\[\\n     35 = 5 \\\\times 7 \\\\quad \\\\text{and} \\\\quad 5 + 7 = 12\\n     \\\\]\\n     This works. So \\\\( p = 5 \\\\) and \\\\( q = 7 \\\\).\\n\\n7. **Find \\\\( r \\\\):**\\n   \\\\[\\n   r = S + 1 = 12 + 1 = 13\\n   \\\\]\\n\\n8. **Verify the solution:**\\n   - Check \\\\( pq + qr + rp = 191 \\\\):\\n     \\\\[\\n     5 \\\\times 7 + 7 \\\\times 13 + 13 \\\\times 5 = 35 + 91 + 65 = 191\\n     \\\\]\\n   - Check \\\\( p + q = r - 1 \\\\):\\n     \\\\[\\n     5 + 7 = 12 \\\\quad \\\\text{and} \\\\quad 13 - 1 = 12\\n     \\\\]\\n\\nSince all conditions are satisfied, the final answer is:\\n\\\\[\\n\\\\boxed{25}\\n\\\\]\",\n          \"<think>\\nOkay, let's see. I need to solve this problem where x and y are positive integers satisfying 2(x + y) = gcd(x, y) + lcm(x, y). And I have to find the ratio of the lcm to the gcd of x and y. Hmm, okay, let's break this down.\\n\\nFirst, I remember that for any two positive integers, the product of the lcm and gcd of those numbers is equal to the product of the numbers themselves. So, lcm(x, y) * gcd(x, y) = x * y. That might come in handy here. Let me note that down: lcm(x,y)*gcd(x,y) = x*y.\\n\\nGiven the equation 2(x + y) = gcd(x, y) + lcm(x, y), maybe I can express everything in terms of gcd and the ratio of x and y. Since gcd and lcm are involved, it might be helpful to let d = gcd(x, y), and then express x and y as x = d*a and y = d*b, where a and b are coprime integers (their gcd is 1). That's a standard approach for problems involving gcd and lcm.\\n\\nSo let me set d = gcd(x, y). Then x = d*a, y = d*b, with gcd(a, b) = 1. Then, the lcm(x, y) would be d*a*b, because lcm(x, y) = x*y / gcd(x, y) = (d*a*d*b)/d = d*a*b. Right, so lcm(x,y) = d*a*b.\\n\\nSubstituting these into the original equation: 2(x + y) = gcd(x, y) + lcm(x, y).\\n\\nSubstituting x = d*a, y = d*b, gcd = d, lcm = d*a*b. Then:\\n\\n2(d*a + d*b) = d + d*a*b.\\n\\nFactor out d from the left side: 2d(a + b) = d(1 + a*b).\\n\\nSince d is a positive integer, we can divide both sides by d, yielding:\\n\\n2(a + b) = 1 + a*b.\\n\\nSo now the equation simplifies to 2(a + b) = a*b + 1, where a and b are coprime positive integers. Hmm, okay. Now we have a simpler equation to solve: a*b - 2a - 2b + 1 = 0. Let me rearrange that:\\n\\na*b - 2a - 2b + 1 = 0.\\n\\nHmm, maybe factor this equation? Let me see. Adding 4 to both sides might help in factoring. Let's try:\\n\\na*b - 2a - 2b + 1 + 4 - 4 = 0\\n\\nSo, a*b - 2a - 2b + 4 = 3.\\n\\nWait, not sure. Alternatively, perhaps rearrange the terms:\\n\\na*b - 2a - 2b = -1.\\n\\nThen, add 4 to both sides:\\n\\na*b - 2a - 2b + 4 = 3.\\n\\nNow, left side can be factored as (a - 2)(b - 2) = 3. Because expanding (a - 2)(b - 2) gives a*b - 2a - 2b + 4. Yes, that's right. So:\\n\\n(a - 2)(b - 2) = 3.\\n\\nSince a and b are positive integers and coprime, we need to find pairs (a, b) such that their product is 3 when each is reduced by 2. Also, since a and b are coprime, (a - 2) and (b - 2) must be divisors of 3, which is prime. The positive divisors of 3 are 1 and 3.\\n\\nSo possible pairs (since a and b are positive integers, a - 2 and b - 2 must be at least such that a and b are positive. Let's see:\\n\\nCase 1: (a - 2) = 1 and (b - 2) = 3. Then, a = 3, b = 5. Check if gcd(a, b) = 1. gcd(3, 5) = 1, which is good.\\n\\nCase 2: (a - 2) = 3 and (b - 2) = 1. Then, a = 5, b = 3. Similarly, gcd(5, 3) = 1. So this is also valid.\\n\\nBut also, since 3 is prime, the only positive divisors are 1 and 3. But since we're considering positive integers, we could also consider if one of them is negative? But since a and b are positive, a - 2 and b - 2 must be positive or zero? Wait, but 3 is positive, so the factors must both be positive. Because if one of (a - 2) or (b - 2) were negative, their product would be negative, but 3 is positive. So both (a - 2) and (b - 2) must be positive. Thus, only the two cases above.\\n\\nAlternatively, maybe (a - 2) and (b - 2) could be 3 and 1 in some order, which gives the two cases. So the possible (a, b) are (3, 5) and (5, 3). Since a and b are interchangeable (since x and y are symmetric in the problem), these two cases would yield the same results.\\n\\nSo now, let's see. For (a, b) = (3, 5), then x = d*3, y = d*5. Similarly, for (a, b) = (5, 3), x = d*5, y = d*3. But since the problem is symmetric in x and y, both cases are equivalent.\\n\\nNow, since we need to find the ratio lcm(x, y)/gcd(x, y), let's compute that.\\n\\nRecall that lcm(x, y)/gcd(x, y) = (d*a*b)/d = a*b. So it's simply a*b. Since in both cases, a and b are 3 and 5, the product is 15. Therefore, the ratio is 15.\\n\\nWait, that seems too straightforward. Let me check.\\n\\nIf the ratio is a*b, then yes. Because lcm(x, y) is d*a*b and gcd(x, y) is d, so their ratio is (d*a*b)/d = a*b. Since a and b are 3 and 5, 3*5=15. Therefore, the answer is 15. So the answer is 15.\\n\\nBut let me verify with an example. Let's take d=1. Then x=3, y=5. Then gcd(3,5)=1, lcm=15. Then 2(x + y) = 2*(8) = 16. The right side is 1 + 15=16. So that works. If d=1, then 2(3+5)=16=1 +15.\\n\\nWhat if d=2? Then x=6, y=10. gcd(6,10)=2, lcm=30. Then 2(6 + 10)=2*16=32. The right side is 2 +30=32. So that also works. Then the ratio lcm/gcd is 30/2=15. So regardless of d, the ratio is always 15. Wait, because if x = d*a, y = d*b, then lcm(x,y)/gcd(x,y) = (d*a*b)/d = a*b, which is 15 as in the first case. So regardless of d, the ratio is always 15. Therefore, the answer is 15.\\n\\nSo even if d is some other positive integer, the ratio remains a*b =15. Therefore, the required ratio is 15.\\n\\nTherefore, the answer is 15. So \\\\boxed{15}.\\n\\n**Final Answer**\\n\\\\boxed{15}\\n</think>Given \\\\( x \\\\) and \\\\( y \\\\) are positive integers such that \\\\( 2(x + y) = \\\\gcd(x, y) + \\\\text{lcm}(x, y) \\\\), we need to find \\\\( \\\\frac{\\\\text{lcm}(x, y)}{\\\\gcd(x, y)} \\\\).\\n\\nFirst, let \\\\( d = \\\\gcd(x, y) \\\\). Then, we can express \\\\( x \\\\) and \\\\( y \\\\) as \\\\( x = d \\\\cdot a \\\\) and \\\\( y = d \\\\cdot b \\\\), where \\\\( \\\\gcd(a, b) = 1 \\\\). The least common multiple (lcm) of \\\\( x \\\\) and \\\\( y \\\\) is given by \\\\( \\\\text{lcm}(x, y) = d \\\\cdot a \\\\cdot b \\\\).\\n\\nSubstituting these into the given equation:\\n\\\\[\\n2(d \\\\cdot a + d \\\\cdot b) = d + d \\\\cdot a \\\\cdot b\\n\\\\]\\nDividing both sides by \\\\( d \\\\):\\n\\\\[\\n2(a + b) = 1 + a \\\\cdot b\\n\\\\]\\nRearranging terms, we get:\\n\\\\[\\na \\\\cdot b - 2a - 2b + 1 = 0\\n\\\\]\\nAdding 4 to both sides to factorize:\\n\\\\[\\na \\\\cdot b - 2a - 2b + 4 = 3\\n\\\\]\\nThis can be factored as:\\n\\\\[\\n(a - 2)(b - 2) = 3\\n\\\\]\\nThe positive integer solutions for \\\\((a - 2)\\\\) and \\\\((b - 2)\\\\) are 1 and 3. Thus, the possible pairs \\\\((a, b)\\\\) are \\\\((3, 5)\\\\) and \\\\((5, 3)\\\\). Since \\\\( a \\\\) and \\\\( b \\\\) are coprime, both pairs are valid.\\n\\nThe ratio \\\\( \\\\frac{\\\\text{lcm}(x, y)}{\\\\gcd(x, y)} \\\\) is given by:\\n\\\\[\\n\\\\frac{\\\\text{lcm}(x, y)}{\\\\gcd(x, y)} = \\\\frac{d \\\\cdot a \\\\cdot b}{d} = a \\\\cdot b\\n\\\\]\\nFor both pairs \\\\((3, 5)\\\\) and \\\\((5, 3)\\\\), the product \\\\( a \\\\cdot b = 15 \\\\).\\n\\nThus, the final answer is:\\n\\\\[\\n\\\\boxed{15}\\n\\\\]\",\n          \"<think>\\nOkay, so I need to find the remainder when the product of all odd numbers from 1 to 2005 is divided by 1000. Hmm, let's think about how to approach this. \\n\\nFirst, the product is 1 \\u00d7 3 \\u00d7 5 \\u00d7 ... \\u00d7 2005. That's a lot of numbers! Since we're dealing with division by 1000, maybe modular arithmetic can help here. The remainder when divided by 1000 is equivalent to the product modulo 1000. But calculating such a huge product directly seems impossible. There has to be a smarter way.\\n\\nI remember that when dealing with factorials and remainders, factors of 2 and 5 can create trailing zeros. However, here we're only multiplying odd numbers, so there are no factors of 2. But there might still be factors of 5. Wait, 1000 is 8\\u00d7125, which is 2^3 \\u00d7 5^3. Since the product is all odd numbers, it won't have factors of 2, but it can have factors of 5. Therefore, the product will be divisible by 5^3, but since there are no 2s, the product modulo 1000 might not be zero. Hmm, maybe I need to compute the product modulo 1000, but adjusting for the factors of 5?\\n\\nAlternatively, maybe split the problem into modulo 8 and modulo 125, then use the Chinese Remainder Theorem (CRT) to combine the results. Since 1000 = 8 \\u00d7 125, and 8 and 125 are coprime, CRT says that if I can find the remainder modulo 8 and modulo 125, then I can combine them to find the remainder modulo 1000. That might be a good approach.\\n\\nLet me start with modulo 8. The product is 1\\u00d73\\u00d75\\u00d77\\u00d79\\u00d7...\\u00d72005. But modulo 8, odd numbers repeat every 8 numbers. Let's see, the residues modulo 8 of odd numbers are 1,3,5,7,1,3,5,7,... So the pattern repeats every 4 terms. Wait, no. Wait, the numbers go 1,3,5,7,9\\u22611,11\\u22613,13\\u22615,15\\u22617, etc. So every 8 numbers, the cycle of residues 1,3,5,7 repeats twice. Wait, actually, modulo 8, the odd residues cycle every 4 numbers. Let's confirm:\\n\\n1 mod 8 =1\\n\\n3 mod8=3\\n\\n5 mod8=5\\n\\n7 mod8=7\\n\\n9 mod8=1\\n\\n11 mod8=3\\n\\n13 mod8=5\\n\\n15 mod8=7\\n\\nYes, every 4 terms, the cycle repeats. So how many terms are in the product 1\\u00d73\\u00d75\\u00d7...\\u00d72005? Let's find the number of terms first. The nth odd number is 2n-1. So 2n-1=2005 => n=(2005+1)/2=2006/2=1003. So there are 1003 terms.\\n\\nSo 1003 terms, each group of 4 terms (mod8) is 1\\u00d73\\u00d75\\u00d77=105. Then 105 mod8= 105 - 13\\u00d78=105-104=1. So each group of 4 terms multiplies to 1 mod8. Then how many full groups of 4 are there in 1003 terms? Let's divide 1003 by 4. 1003 \\u00f74=250.75. So 250 full groups, each contributing 1 mod8, and then a remainder of 3 terms. \\n\\nSo the total product modulo8 is (1^250) \\u00d7 (last three terms). The last three terms would be the terms after the 250th group. The 250th group ends at term 250\\u00d74=1000. So the 1001st term is 2\\u00d71001 -1=2001. Wait, no: the first term is 1=2\\u00d71-1, second term 3=2\\u00d72-1, so term k is 2k-1. Therefore, term 1001 is 2\\u00d71001 -1=2002-1=2001. Then the 1002nd term is 2003, 1003rd term is 2005. So the last three terms are 2001, 2003, 2005. Let's compute each mod8:\\n\\n2001 \\u00f78: 8\\u00d7250=2000, so 2001 mod8=1\\n\\n2003 mod8=3\\n\\n2005 mod8=5\\n\\nSo the last three terms modulo8 are 1\\u00d73\\u00d75=15 mod8=7.\\n\\nTherefore, total product mod8 is (1^250) \\u00d77=1\\u00d77=7 mod8.\\n\\nSo the remainder modulo8 is7.\\n\\nNow, we need to compute the product modulo125. This seems more complicated. Let's think.\\n\\nThe product is the product of all odd numbers from1 to2005. Wait, 2005=5\\u00d7401. So we can write the product as (1\\u00d73\\u00d75\\u00d77\\u00d7...\\u00d72005). Let's note that there are a lot of factors of 5 in this product, which would make the product divisible by 5 multiple times. However, modulo125 is 5^3, so if the product has at least three factors of 5, then modulo125 would be 0. Wait, but maybe even if it's divisible by 5^3, but we need to compute the actual remainder. Wait, but perhaps the product is divisible by 5^3, but when divided by 5^3, the remaining product modulo8 or something else. Wait, maybe not. Let me check how many factors of5 are in the product.\\n\\nThe number of factors of5 in the product:\\n\\nEach multiple of5 contributes at least one factor of5. Since we're dealing with odd numbers, the multiples of5 that are odd. So numbers divisible by5 but not by2. So numbers like5,15,25,...,2005. Let's count how many multiples of5 are in the product. The first term is5, which is5\\u00d71, then15=5\\u00d73,..., up to2005=5\\u00d7401. So the multiples of5 are5\\u00d7(1,3,5,...,401). Wait, 5\\u00d7k, where k is odd from1 to401. Because 5\\u00d7401=2005. So how many terms are there?\\n\\nThe number of terms k from1 to401 where k is odd. Since401 is odd, the number is (401 +1)/2=201. So there are201 multiples of5 in the product. Each contributes at least one factor of5. Additionally, multiples of25 contribute an extra factor of5. Similarly, multiples of125, 625, etc., contribute more factors.\\n\\nSo let's compute the total number of factors of5 in the product.\\n\\nNumber of multiples of5:201 (as above)\\n\\nNumber of multiples of25: These are numbers in the product divisible by25. Since the product includes numbers of the form5\\u00d7(odd numbers). So multiples of25 are numbers divisible by25, which are 25,75,125,...,2000. But 2005 is not divisible by25. Wait, wait, in the original product (all odd numbers up to2005), the multiples of25 must be odd multiples. So 25\\u00d71,25\\u00d73,..., up to the largest odd multiple less than or equal to2005.\\n\\n25\\u00d7k \\u22642005, where k is odd. Let's compute k_max:\\n\\n25k \\u22642005 => k \\u22642005/25=80.2. So the largest integer k is80, but since k has to be odd, the largest odd k is79. So 25\\u00d779=1975. Then 25\\u00d781=2025, which is over. So the multiples of25 in the product are25\\u00d71,25\\u00d73,...,25\\u00d779. Number of terms: (79-1)/2 +1=39 +1=40. Wait, from1 to79 odd numbers: number is (79+1)/2=40. So there are40 multiples of25.\\n\\nSimilarly, multiples of125:125\\u00d71,125\\u00d73,..., up to125\\u00d7k\\u22642005. 125\\u00d7k \\u22642005 =>k\\u226416.04. So k_max=15 (odd). So 125\\u00d715=1875. So multiples are125\\u00d71,125\\u00d73,...,125\\u00d715. Number of terms: (15-1)/2 +1=7+1=8.\\n\\nMultiples of625:625\\u00d71=625, next is625\\u00d73=1875, next is625\\u00d75=3125>2005. So only two multiples:625 and1875. But1875 is already counted as a multiple of125. So factors of625 contribute an extra factor of5 each. So number of multiples of625 is 2. 625 and1875.\\n\\nMultiples of3125:3125>2005, so none.\\n\\nSo total number of factors of5:\\n\\nFrom multiples of5:201\\n\\nFrom multiples of25:40 (each contributes an extra)\\n\\nFrom multiples of125:8 (each contributes another extra)\\n\\nFrom multiples of625:2 (each contributes another extra)\\n\\nTotal:201 +40 +8 +2=251.\\n\\nSo total factors of5 in the product:251.\\n\\nSimilarly, factors of2: since all numbers are odd, there are none. So the product is divisible by5^251 but not by2. So when dividing by5^3, since 251\\u22653, the product is divisible by5^3. Therefore, the product modulo125 is0? Wait, no, wait. Wait, 125 is5^3. If the product has at least three factors of5, then when divided by5^3, the quotient is an integer, but the remainder when divided by125 is0. So if the product is divisible by125, then the remainder is0. But the question is, when we divide the product by1000, which is8\\u00d7125, the remainder is to be found. However, we already considered that modulo8 is7, and modulo125 is... Hmm, but if modulo125 is0, then using CRT, we can say the remainder is a number congruent to7 mod8 and0 mod125. So we need to solve for x\\u22610 mod125 andx\\u22617 mod8.\\n\\nBut wait, let me confirm if modulo125 is indeed0. Let's check: since the product has at least three factors of5, then yes, the product is divisible by5^3, so product \\u22610 mod125. Therefore, modulo125 is0. Therefore, we have:\\n\\nx \\u22617 mod8\\n\\nx \\u22610 mod125\\n\\nWe need to find x such that x \\u22610 mod125 andx \\u22617 mod8. Let\\u2019s solve this system.\\n\\nLet x=125k. Then 125k\\u22617 mod8. Since125 mod8=5, so 5k\\u22617 mod8.\\n\\nWe solve 5k\\u22617 mod8.\\n\\nMultiply both sides by inverse of5 mod8. The inverse of5 mod8 is5, since5\\u00d75=25\\u22611 mod8. So multiply both sides by5:\\n\\nk\\u22617\\u00d75 mod8 =>k\\u226135 mod8 =>35\\u00f78=4*8=32, 35-32=3. So k\\u22613 mod8.\\n\\nTherefore, k=8m +3 for some integer m. Therefore, x=125(8m +3)=1000m +375. Therefore, the smallest non-negative solution is375. Therefore, the remainder is375 when divided by1000. So the answer is375.\\n\\nWait, but before accepting that, let me verify my steps again because this is tricky.\\n\\nFirst, confirming that the product is divisible by5^3: yes, since there are 251 factors of5, so 5^251 divides the product. Therefore, the product is divisible by5^3, so product\\u22610 mod125. That's correct.\\n\\nThen, solving x\\u22617 mod8 and x\\u22610 mod125. So x=125k. Then 125k\\u22615k mod8. So 5k\\u22617 mod8. Multiply both sides by inverse of5 mod8, which is5, since5\\u00d75=25\\u22611 mod8. So k\\u226135 mod8\\u22613 mod8. Therefore, k=8m +3, so x=125\\u00d73 +1000m=375 +1000m. So the minimal positive solution is375. So remainder is375 when divided by1000. That seems correct.\\n\\nBut wait, to make sure, let me check with an example. Let's take x=375. 375 \\u00f78=46*8=368, remainder7. So 375 mod8=7. 375 mod125=0. So yes, 375 satisfies both conditions. Therefore, the remainder is375. Therefore, the answer is\\\\boxed{375}.\\n\\nWait, but I need to make sure that my calculation for modulo8 and modulo125 are correct. Let me double-check the modulo8 calculation.\\n\\nEarlier, I considered that the product modulo8 is7. Let me recast that.\\n\\nThe product is1\\u00d73\\u00d75\\u00d77\\u00d7\\u2026\\u00d72005. When taking modulo8, each cycle of4 terms (1,3,5,7) multiplies to1\\u00d73\\u00d75\\u00d77=105\\u22611 mod8. Since 105/8=13\\u00d78=104, 105-104=1. Then, since there are1003 terms, how many cycles of4 are there? 1003 divided by4 is250 cycles with a remainder of3 terms. Then the product is (1)^250 \\u00d7 last3 terms.\\n\\nThe last3 terms are2001,2003,2005. 2001 mod8=1 (2001-8\\u00d7250=2001-2000=1), 2003=2001+2\\u21921+2=3 mod8, 2005=2001+4\\u21921+4=5 mod8. So last3 terms are1\\u00d73\\u00d75=15\\u22617 mod8. Therefore, total product\\u22611^250 \\u00d77\\u22617 mod8. Correct.\\n\\nTherefore, the logic holds. Therefore, the remainder is375. So I think that's the correct answer.\\n\\n**Final Answer**\\n\\\\boxed{375}\\n</think>To find the remainder when the product \\\\(1 \\\\times 3 \\\\times 5 \\\\times \\\\cdots \\\\times 2005\\\\) is divided by 1000, we use modular arithmetic and the Chinese Remainder Theorem (CRT).\\n\\n### Step 1: Calculate the product modulo 8\\n\\nThe sequence of odd numbers modulo 8 repeats every 4 terms: \\\\(1, 3, 5, 7\\\\). The product of each cycle is:\\n\\\\[\\n1 \\\\times 3 \\\\times 5 \\\\times 7 = 105 \\\\equiv 1 \\\\mod 8\\n\\\\]\\n\\nThere are 1003 terms in the product. Dividing 1003 by 4 gives 250 full cycles and a remainder of 3 terms. The remaining terms are 2001, 2003, and 2005. We calculate these modulo 8:\\n\\\\[\\n2001 \\\\equiv 1 \\\\mod 8, \\\\quad 2003 \\\\equiv 3 \\\\mod 8, \\\\quad 2005 \\\\equiv 5 \\\\mod 8\\n\\\\]\\nThe product of these remaining terms is:\\n\\\\[\\n1 \\\\times 3 \\\\times 5 = 15 \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\nThus, the product modulo 8 is:\\n\\\\[\\n1^{250} \\\\times 7 \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\n### Step 2: Calculate the product modulo 125\\n\\nWe need to determine the number of factors of 5 in the product. The sequence of odd numbers includes multiples of 5, 25, 125, and 625.\\n\\n- Multiples of 5: \\\\(5, 15, 25, \\\\ldots, 2005\\\\)\\n  - These are of the form \\\\(5 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1, 2, \\\\ldots, 200\\\\)\\n  - Number of such terms: \\\\(\\\\frac{2005}{5} = 401\\\\), and half of these are odd, so \\\\(201\\\\) multiples of 5.\\n\\n- Multiples of 25: \\\\(25, 75, 125, \\\\ldots, 1975\\\\)\\n  - These are of the form \\\\(25 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1, 2, \\\\ldots, 39\\\\)\\n  - Number of such terms: \\\\(\\\\frac{1975}{25} = 79\\\\), and half of these are odd, so \\\\(40\\\\) multiples of 25.\\n\\n- Multiples of 125: \\\\(125, 375, 625, 875, 1125, 1375, 1625, 1875\\\\)\\n  - These are of the form \\\\(125 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1, 2, \\\\ldots, 15\\\\)\\n  - Number of such terms: \\\\(\\\\frac{1875}{125} = 15\\\\), and half of these are odd, so \\\\(8\\\\) multiples of 125.\\n\\n- Multiples of 625: \\\\(625, 1875\\\\)\\n  - These are of the form \\\\(625 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1\\\\)\\n  - Number of such terms: \\\\(\\\\frac{1875}{625} = 3\\\\), and half of these are odd, so \\\\(2\\\\) multiples of 625.\\n\\nTotal factors of 5:\\n\\\\[\\n201 + 40 + 8 + 2 = 251\\n\\\\]\\n\\nSince \\\\(251 \\\\geq 3\\\\), the product is divisible by \\\\(5^3 = 125\\\\). Therefore, the product modulo 125 is:\\n\\\\[\\n0 \\\\mod 125\\n\\\\]\\n\\n### Step 3: Combine results using the Chinese Remainder Theorem\\n\\nWe have:\\n\\\\[\\nx \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\\\[\\nx \\\\equiv 0 \\\\mod 125\\n\\\\]\\n\\nLet \\\\(x = 125k\\\\). Then:\\n\\\\[\\n125k \\\\equiv 7 \\\\mod 8\\n\\\\]\\nSince \\\\(125 \\\\equiv 5 \\\\mod 8\\\\), we have:\\n\\\\[\\n5k \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\nThe multiplicative inverse of 5 modulo 8 is 5, so:\\n\\\\[\\nk \\\\equiv 7 \\\\times 5 \\\\equiv 35 \\\\equiv 3 \\\\mod 8\\n\\\\]\\n\\nThus, \\\\(k = 8m + 3\\\\) for some integer \\\\(m\\\\). Therefore:\\n\\\\[\\nx = 125(8m + 3) = 1000m + 375\\n\\\\]\\n\\nThe smallest non-negative solution is:\\n\\\\[\\nx = 375\\n\\\\]\\n\\nTherefore, the remainder when the product is divided by 1000 is:\\n\\\\[\\n\\\\boxed{375}\\n\\\\]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to format the dataset to follow our GRPO style formatting:"
      ],
      "metadata": {
        "id": "JVRFqoSdIEVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(x):\n",
        "    expected_answer = x[\"expected_answer\"]\n",
        "    problem = x[\"problem\"]\n",
        "\n",
        "    # Remove generated <think> and </think>\n",
        "    thoughts = x[\"generated_solution\"]\n",
        "    thoughts = thoughts.replace(\"<think>\", \"\").replace(\"</think>\", \"\")\n",
        "\n",
        "    # Strip newlines on left and right\n",
        "    thoughts = thoughts.strip()\n",
        "    # Add our custom formatting\n",
        "    final_prompt = \\\n",
        "        reasoning_start + thoughts + reasoning_end + \\\n",
        "        solution_start + expected_answer + solution_end\n",
        "    return [\n",
        "        {\"role\" : \"system\",    \"content\" : system_prompt},\n",
        "        {\"role\" : \"user\",      \"content\" : problem},\n",
        "        {\"role\" : \"assistant\", \"content\" : final_prompt},\n",
        "    ]\n",
        "\n",
        "dataset[\"Messages\"] = dataset.apply(format_dataset, axis = 1)"
      ],
      "metadata": {
        "id": "Z9ydcV_Abfi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check to see if it worked:"
      ],
      "metadata": {
        "id": "X5NI47rOIRP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.apply_chat_template(dataset[\"Messages\"][0], tokenize = False)"
      ],
      "metadata": {
        "id": "LTdXBKcslhRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "a7a2ea50-2531-4577-a489-12ae07b0e454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION><|endoftext|>Given $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.<start_working_out>Okay, let's see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, and find all positive values of x. Hmm, radicals can be tricky, but maybe if I can eliminate the square roots by squaring both sides. Let me try that.\\n\\nFirst, let me write down the equation again to make sure I have it right:\\n\\n√(x² + 165) - √(x² - 52) = 7.\\n\\nOkay, so the idea is to isolate one of the radicals and then square both sides. Let me try moving the second radical to the other side:\\n\\n√(x² + 165) = 7 + √(x² - 52).\\n\\nNow, if I square both sides, maybe I can get rid of the square roots. Let's do that:\\n\\n(√(x² + 165))² = (7 + √(x² - 52))².\\n\\nSimplifying the left side:\\n\\nx² + 165 = 49 + 14√(x² - 52) + (√(x² - 52))².\\n\\nThe right side is expanded using the formula (a + b)² = a² + 2ab + b². So the right side becomes 7² + 2*7*√(x² - 52) + (√(x² - 52))², which is 49 + 14√(x² - 52) + (x² - 52).\\n\\nSo putting it all together:\\n\\nx² + 165 = 49 + 14√(x² - 52) + x² - 52.\\n\\nHmm, let's simplify the right side. The x² terms will cancel out, right? Let's subtract x² from both sides:\\n\\n165 = 49 + 14√(x² - 52) - 52.\\n\\nSimplify the constants on the right:\\n\\n49 - 52 is -3, so:\\n\\n165 = -3 + 14√(x² - 52).\\n\\nNow, add 3 to both sides to isolate the radical term:\\n\\n165 + 3 = 14√(x² - 52).\\n\\nSo 168 = 14√(x² - 52).\\n\\nDivide both sides by 14:\\n\\n168 / 14 = √(x² - 52).\\n\\n12 = √(x² - 52).\\n\\nNow, square both sides again to eliminate the square root:\\n\\n12² = x² - 52.\\n\\n144 = x² - 52.\\n\\nAdd 52 to both sides:\\n\\n144 + 52 = x².\\n\\n196 = x².\\n\\nSo x = √196 = 14.\\n\\nBut wait, since the problem states that x is positive, we only take the positive root. So x = 14.\\n\\nBut hold on, when dealing with squaring equations, sometimes extraneous solutions can come up. I should check if this solution actually satisfies the original equation.\\n\\nLet's plug x = 14 back into the original equation:\\n\\n√(14² + 165) - √(14² - 52) = ?\\n\\nCalculate each term:\\n\\n14² is 196.\\n\\nSo first radical: √(196 + 165) = √361 = 19.\\n\\nSecond radical: √(196 - 52) = √144 = 12.\\n\\nSo 19 - 12 = 7, which is exactly the right-hand side. So yes, it checks out.\\n\\nTherefore, the only solution is x = 14. Since the problem says x is positive, we don't have to consider negative roots. So I think that's the answer.\\nTo solve the equation \\\\(\\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\\\) for positive \\\\(x\\\\), we proceed as follows:\\n\\n1. Start with the given equation:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\n   \\\\]\\n\\n2. Isolate one of the square roots by moving \\\\(\\\\sqrt{x^2 - 52}\\\\) to the right side:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} = 7 + \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n3. Square both sides to eliminate the square root on the left:\\n   \\\\[\\n   (\\\\sqrt{x^2 + 165})^2 = (7 + \\\\sqrt{x^2 - 52})^2\\n   \\\\]\\n   Simplifying both sides, we get:\\n   \\\\[\\n   x^2 + 165 = 49 + 14\\\\sqrt{x^2 - 52} + (x^2 - 52)\\n   \\\\]\\n\\n4. Combine like terms on the right side:\\n   \\\\[\\n   x^2 + 165 = x^2 - 52 + 49 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n   Simplifying further:\\n   \\\\[\\n   x^2 + 165 = x^2 - 3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n5. Subtract \\\\(x^2\\\\) from both sides:\\n   \\\\[\\n   165 = -3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n6. Add 3 to both sides to isolate the term with the square root:\\n   \\\\[\\n   168 = 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n7. Divide both sides by 14:\\n   \\\\[\\n   12 = \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n8. Square both sides again to eliminate the square root:\\n   \\\\[\\n   12^2 = x^2 - 52\\n   \\\\]\\n   Simplifying:\\n   \\\\[\\n   144 = x^2 - 52\\n   \\\\]\\n\\n9. Add 52 to both sides to solve for \\\\(x^2\\\\):\\n   \\\\[\\n   196 = x^2\\n   \\\\]\\n\\n10. Take the positive square root (since \\\\(x\\\\) is positive):\\n    \\\\[\\n    x = \\\\sqrt{196} = 14\\n    \\\\]\\n\\n11. Verify the solution by substituting \\\\(x = 14\\\\) back into the original equation:\\n    \\\\[\\n    \\\\sqrt{14^2 + 165} - \\\\sqrt{14^2 - 52} = \\\\sqrt{196 + 165} - \\\\sqrt{196 - 52} = \\\\sqrt{361} - \\\\sqrt{144} = 19 - 12 = 7\\n    \\\\]\\n    The solution checks out.\\n\\nThus, the only positive solution is:\\n\\\\[\\n\\\\boxed{14}\\n\\\\]<end_working_out><SOLUTION>14</SOLUTION><|endoftext|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's truncate the pre fine-tuning dataset to `max_seq_length/2` since we don't want too long reasoning traces.\n",
        "\n",
        "Note this might take 2 minutes!"
      ],
      "metadata": {
        "id": "iHV9BXYiIYaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"N\"] = dataset[\"Messages\"].apply(lambda x: len(tokenizer.apply_chat_template(x)))\n",
        "\n",
        "dataset = dataset.loc[dataset[\"N\"] <= max_seq_length/2].copy()\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "MBHFlRbae9_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29851a0b-6f33-4d8a-d18f-a534214b2488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then tokenize the messages and convert it to a Hugging Face compatible dataset format:"
      ],
      "metadata": {
        "id": "E6NkUCAGIj8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset[\"text\"] = tokenizer.apply_chat_template(dataset[\"Messages\"].values.tolist(), tokenize = False)\n",
        "dataset = Dataset.from_pandas(dataset)\n",
        "dataset"
      ],
      "metadata": {
        "id": "3rgdtiV_f5hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed04407-e366-4e01-aa2e-ce81185636cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['expected_answer', 'problem', 'generated_solution', 'Messages', 'N', 'text', '__index_level_0__'],\n",
              "    num_rows: 59\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now pre fine-tune the model so it follows our custom GRPO formatting!"
      ],
      "metadata": {
        "id": "bAQJjQrYKzOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        per_device_train_batch_size = 1,\n",
        "        gradient_accumulation_steps = 1, # Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 2, # Set this for 1 full training run.\n",
        "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
        "        logging_steps = 5,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "woYi0SSygpqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5e32cde8bae04944acb9b81d72083d9e",
            "8c310891371442e7ace9bb2cb427f157",
            "e79bc585dceb4cf78d07b006517de7da",
            "acab127a93654604ae5c7b2b3241e262",
            "12630f33d40541b6bcb63b86be4b340c",
            "dcd27e26dd6c4f5a80d4ee674e3a1941",
            "13ac50082b6744a2b70b2bf785b5299c",
            "e2bb8a2af8ba451fa113d77556080d3e",
            "8a4ffe2fa4e04945b816752992077a79",
            "d796eb8672674433ba1d6378d7140623",
            "44e07fc58e3e44fb9223e7cec91847d6"
          ]
        },
        "outputId": "fd97d068-1581-4c1b-b1f9-d0793ce094a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/59 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e32cde8bae04944acb9b81d72083d9e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "l4-2v_bLhZuE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "a1745d11-fded-4845-a5bd-3ccde20021f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 59 | Num Epochs = 2 | Total steps = 118\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 1 x 1) = 1\n",
            " \"-____-\"     Trainable parameters = 66,060,288/4,088,528,384 (1.62% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [118/118 02:40, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.644800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.639700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.419300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.389500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.422300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.448200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.419200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.328500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.453300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.247000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.244800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.301200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.226400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.211200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.258900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.190800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.260300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.255000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.217400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.180300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=118, training_loss=0.34849793122986616, metrics={'train_runtime': 162.2519, 'train_samples_per_second': 0.727, 'train_steps_per_second': 0.727, 'total_flos': 2374193075607552.0, 'train_loss': 0.34849793122986616})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if the model has learnt to follow the custom format:"
      ],
      "metadata": {
        "id": "DRMBNUBgLC8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    dataset[0][\"Messages\"][:2],\n",
        "    tokenize = False,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        ")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
        "    temperature = 0,\n",
        "    max_new_tokens = 1024,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
        ")"
      ],
      "metadata": {
        "id": "9HJxrS76h3Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e53c6e-6af4-4c52-cf18-197524dbddfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are given a problem.\n",
            "Think about the problem and provide your working out.\n",
            "Place it between <start_working_out> and <end_working_out>.\n",
            "Then, provide your solution between <SOLUTION></SOLUTION><|endoftext|>Jenifer has 82 cents in pennies and nickels. Her younger brother mistook all her nickels for dimes and counted the total as $1.47. How many pennies does Jenifer have?<start_working_out>Okay, let's see. Jenifer has 82 cents in pennies and nickels. Her younger brother thought all the nickels were dimes and counted the total as $1.47. I need to find out how many pennies Jenifer has. Hmm, let's break this down step by step.\n",
            "\n",
            "First, I need to set up some equations. Let's say the number of pennies is P and the number of nickels is N. Since pennies are worth 1 cent each and nickels are 5 cents each, the total value Jenifer has is:\n",
            "\n",
            "P + 5N = 82 cents.\n",
            "\n",
            "Now, her brother thought all the nickels were dimes. Dimes are 10 cents each. So, he counted the total as $1.47, which is 147 cents. So, the equation based on his mistaken count would be:\n",
            "\n",
            "P + 10N = 147 cents.\n",
            "\n",
            "Now, I have two equations:\n",
            "\n",
            "1) P + 5N = 82\n",
            "2) P + 10N = 147\n",
            "\n",
            "I need to solve these two equations to find P. Let me think. Since both equations have P, maybe I can subtract the first equation from the second to eliminate P. Let's try that.\n",
            "\n",
            "Subtract equation 1 from equation 2:\n",
            "\n",
            "(P + 10N) - (P + 5N) = 147 - 82\n",
            "\n",
            "Simplifying the left side: P - P + 10N - 5N = 5N\n",
            "\n",
            "Right side: 147 - 82 = 65\n",
            "\n",
            "So, 5N = 65. Dividing both sides by 5 gives N = 13. So there are 13 nickels.\n",
            "\n",
            "Now, plug N back into the first equation to find P:\n",
            "\n",
            "P + 5(13) = 82\n",
            "\n",
            "5*13 is 65, so P + 65 = 82. Subtract 65 from both sides: P = 82 - 65 = 17.\n",
            "\n",
            "So, Jenifer has 17 pennies. Let me check that. If she has 17 pennies and 13 nickels, that's 17 + 65 = 82 cents, which matches the original amount. Her brother thought the nickels were dimes, so 13 nickels as dimes would be 13*10=130 cents. Adding the 17 pennies gives 130 + 17 = 147 cents, which is $1.47. That checks out. So the answer should be 17 pennies.\n",
            "To solve the problem, we start by defining the variables:\n",
            "- Let \\( P \\) be the number of pennies.\n",
            "- Let \\( N \\) be the number of nickels.\n",
            "\n",
            "We know the following:\n",
            "1. The total value of the pennies and nickels is 82 cents.\n",
            "2. The brother mistakenly counted the nickels as dimes and the total as 147 cents.\n",
            "\n",
            "We can set up the following system of equations based on the given information:\n",
            "1. \\( P + 5N = 82 \\) (value of pennies and nickels)\n",
            "2. \\( P + 10N = 147 \\) (value of pennies and dimes)\n",
            "\n",
            "To find the number of pennies, we can eliminate \\( P \\) by subtracting the first equation from the second:\n",
            "\\[\n",
            "(P + 10N) - (P + 5N) = 147 - 82\n",
            "\\]\n",
            "Simplifying, we get:\n",
            "\\[\n",
            "5N = 65\n",
            "\\]\n",
            "Solving for \\( N \\):\n",
            "\\[\n",
            "N = \\frac{65}{5} = 13\n",
            "\\]\n",
            "\n",
            "Now that we know \\( N = 13 \\), we substitute this value back into the first equation to find \\( P \\):\n",
            "\\[\n",
            "P + 5(13) = 82\n",
            "\\]\n",
            "\\[\n",
            "P + 65 = 82\n",
            "\\]\n",
            "\\[\n",
            "P = 82 - 65 = 17\n",
            "\\]\n",
            "\n",
            "Thus, Jenifer has \\(\\boxed{17}\\) pennies.<end_working_out><SOLUTION>17</SOLUTION><|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it did follow the formatting! Great! Let's remove some items before the GRPO step"
      ],
      "metadata": {
        "id": "AtZ3qGOALF95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWSZ0DET7bob",
        "outputId": "a624be91-d24f-40d9-cfe4-9e637055bad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGgPgk_5S8r"
      },
      "source": [
        "### Data Prep\n",
        "<a name=\"Data\"></a>\n",
        "\n",
        "We're using Hugging Face's [Open R1 Math dataset](https://huggingface.co/datasets/open-r1/DAPO-Math-17k-Processed). You can also utilize OpenAI's famous [GSM8K dataset](https://huggingface.co/datasets/openai/gsm8k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7-eUrQn-OzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59bcd6e9-c4f9-4fba-db25-536ad46bd805"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'solution', 'data_source', 'source_prompt', 'ability', 'reward_model', 'extra_info'],\n",
              "    num_rows: 14116\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"open-r1/DAPO-Math-17k-Processed\", \"en\", split = \"train\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b00gUsS-ROW"
      },
      "source": [
        "Let's look at the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siopxjG8-ReF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4e9cb046-9665-4b10-85da-10e4adf026bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In triangle $ABC$, $\\\\sin \\\\angle A = \\\\frac{4}{5}$ and $\\\\angle A < 90^\\\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\\\angle BAD = \\\\angle DAC$ and $\\\\angle BDC = 90^\\\\circ$. Suppose that $AD = 1$ and that $\\\\frac{BD}{CD} = \\\\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\\\frac{a\\\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset[0][\"prompt\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGupRQqD-Wcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf999c6a-87ff-48a6-deed-fb2d21ca3789"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'34'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "dataset[0][\"solution\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmnXj6hn-Ydi"
      },
      "source": [
        "In GSM8K, ee notice all answers like about have a ####, so we extract it. But for the Open R1 dataset, we can skip the below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JJGXKdJ-Zl_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41544744-1952-4c71-9782-fd023e7afad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'34'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "def extract_hash_answer(text):\n",
        "    # if \"####\" not in text: return None\n",
        "    # return text.split(\"####\")[1].strip()\n",
        "    return text\n",
        "extract_hash_answer(dataset[0][\"solution\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K30CygaU-dir"
      },
      "source": [
        "Let's map the dataset! and see the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyEVI972-d3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27093944-1f22-4263-bc31-e1976e773bcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': [{'content': 'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION>',\n",
              "   'role': 'system'},\n",
              "  {'content': 'In triangle $ABC$, $\\\\sin \\\\angle A = \\\\frac{4}{5}$ and $\\\\angle A < 90^\\\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\\\angle BAD = \\\\angle DAC$ and $\\\\angle BDC = 90^\\\\circ$. Suppose that $AD = 1$ and that $\\\\frac{BD}{CD} = \\\\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\\\frac{a\\\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.',\n",
              "   'role': 'user'}],\n",
              " 'solution': '34',\n",
              " 'data_source': 'math_dapo',\n",
              " 'source_prompt': [{'content': 'Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.\\n\\nIn triangle $ABC$, $\\\\sin \\\\angle A = \\\\frac{4}{5}$ and $\\\\angle A < 90^\\\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\\\angle BAD = \\\\angle DAC$ and $\\\\angle BDC = 90^\\\\circ$. Suppose that $AD = 1$ and that $\\\\frac{BD}{CD} = \\\\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\\\frac{a\\\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.\\n\\nRemember to put your answer on its own line after \"Answer:\".',\n",
              "   'role': 'user'}],\n",
              " 'ability': 'MATH',\n",
              " 'reward_model': {'ground_truth': '34', 'style': 'rule-lighteval/MATH_v2'},\n",
              " 'extra_info': {'index': '9a9b6eb4-a1cb-49d1-8c1e-62eaf2f74079'},\n",
              " 'answer': '34'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: {\n",
        "    \"prompt\" : [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\",   \"content\": x[\"prompt\"]},\n",
        "    ],\n",
        "    \"answer\": extract_hash_answer(x[\"solution\"]),\n",
        "})\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9m8eR9T-gMh"
      },
      "source": [
        "We create a regex format to match the reasoning sections and answers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQwjTjNz-gY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5be1ab-7710-4a3b-e950-74a96a32c1c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "re.compile(r'<end_working_out>.*?<SOLUTION>(.+?)</SOLUTION>[\\s]{0,}(?:<\\|endoftext\\|>)?[\\s]{0,}$',\n",
              "re.MULTILINE|re.DOTALL|re.UNICODE)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Add optional EOS token matching\n",
        "solution_end_regex = r\"</SOLUTION>[\\s]{0,}\" + \\\n",
        "    \"(?:\" + re.escape(tokenizer.eos_token) + \")?\"\n",
        "\n",
        "match_format = re.compile(\n",
        "    rf\"{reasoning_end}.*?\"\\\n",
        "    rf\"{solution_start}(.+?){solution_end_regex}\"\\\n",
        "    rf\"[\\s]{{0,}}$\",\n",
        "    flags = re.MULTILINE | re.DOTALL\n",
        ")\n",
        "match_format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OycMneOq-iNC"
      },
      "source": [
        "We verify it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndzHnQ_6-jHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a8cb7d-4458-48ad-c072-8b03b4c48ae7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n2\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "match_format.findall(\n",
        "    \"Let me think!<end_working_out>\"\\\n",
        "    f\"<SOLUTION>\\n2\\n</SOLUTION>\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_format.findall(\n",
        "    \"<start_working_out>Let me think!<end_working_out>\"\\\n",
        "    f\"<SOLUTION>  2  </SOLUTION>\\n\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "eRMDAzDk2x6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea5b05d-2038-407e-f66a-14824944ff73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  2  ']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weOjmO5l-kl3"
      },
      "source": [
        "We now want to create a reward function to match the format exactly - we reward it with 3 points if it succeeds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgFNXORy-lpO"
      },
      "outputs": [],
      "source": [
        "def match_format_exactly(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        # Match if format is seen exactly!\n",
        "        if match_format.search(response) is not None: score += 3.0\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf69i2WT-m4K"
      },
      "source": [
        "If it fails, we want to reward the model if it at least follows the format partially, by counting each symbol:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUfHzCVx-nGK"
      },
      "outputs": [],
      "source": [
        "def match_format_approximately(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        # Count how many keywords are seen - we penalize if too many!\n",
        "        # If we see 1, then plus some points!\n",
        "\n",
        "        # No need to reward <start_working_out> since we always prepend it!\n",
        "        # score += 0.5 if response.count(reasoning_start) == 1 else -1.0\n",
        "        score += 0.5 if response.count(reasoning_end)   == 1 else -1.0\n",
        "        score += 0.5 if response.count(solution_start)  == 1 else -1.0\n",
        "        score += 0.5 if response.count(solution_end)    == 1 else -1.0\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wAUWwtE-s6n"
      },
      "source": [
        "Finally, we want to extract the generated answer, and reward or penalize it! We also reward it based on how close the answer is to the true one via ratios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmtI_8gg-uIE"
      },
      "outputs": [],
      "source": [
        "def check_answer(prompts, completions, answer, **kwargs):\n",
        "    question = prompts[0][-1][\"content\"]\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [\n",
        "        guess.group(1)\n",
        "        if (guess := match_format.search(r)) is not None else None \\\n",
        "        for r in responses\n",
        "    ]\n",
        "\n",
        "    scores = []\n",
        "    for guess, true_answer in zip(extracted_responses, answer):\n",
        "        score = 0\n",
        "        if guess is None:\n",
        "            scores.append(-2.0)\n",
        "            continue\n",
        "        # Correct answer gets 5 points!\n",
        "        if guess == true_answer:\n",
        "            score += 5.0\n",
        "        # Match if spaces are seen, but less reward\n",
        "        elif guess.strip() == true_answer.strip():\n",
        "            score += 3.5\n",
        "        else:\n",
        "            # We also reward it if the answer is close via ratios!\n",
        "            # Ie if the answer is within some range, reward it!\n",
        "            try:\n",
        "                ratio = float(guess) / float(true_answer)\n",
        "                if   ratio >= 0.9 and ratio <= 1.1: score += 2.0\n",
        "                elif ratio >= 0.8 and ratio <= 1.2: score += 1.5\n",
        "                else: score -= 2.5 # Penalize wrong answers\n",
        "            except:\n",
        "                score -= 4.5 # Penalize\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atMyfhXh-v3R"
      },
      "source": [
        "Also sometimes it might not be 1 number as the answer, but like a sentence for example \"The solution is $20\" -> we extract 20.\n",
        "\n",
        "We also remove possible commas for example as in 123,456"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVW0kL8q-wL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e9c298-1244-457b-ab52-19b9161c7dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.34']\n",
            "['123,456']\n",
            "['-0.234']\n",
            "['17']\n"
          ]
        }
      ],
      "source": [
        "match_numbers = re.compile(\n",
        "    solution_start + r\".*?[\\s]{0,}([-]?[\\d\\.\\,]{1,})\",\n",
        "    flags = re.MULTILINE | re.DOTALL\n",
        ")\n",
        "print(match_numbers.findall(\"<SOLUTION>  0.34  </SOLUTION>\"))\n",
        "print(match_numbers.findall(\"<SOLUTION>  123,456  </SOLUTION>\"))\n",
        "print(match_numbers.findall(\"<SOLUTION>  -0.234  </SOLUTION>\"))\n",
        "print(match_numbers.findall(\"<SOLUTION>17</SOLUTION>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now prepare our main function which will print out the generated responses and the true answer, along with another reward function which converts text to float via `float` and sees if it's the same."
      ],
      "metadata": {
        "id": "RbfaaAywNHHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjBFrttr-y1_"
      },
      "outputs": [],
      "source": [
        "global PRINTED_TIMES\n",
        "PRINTED_TIMES = 0\n",
        "global PRINT_EVERY_STEPS\n",
        "PRINT_EVERY_STEPS = 5\n",
        "\n",
        "def check_numbers(prompts, completions, answer, **kwargs):\n",
        "    question = prompts[0][-1][\"content\"]\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [\n",
        "        guess.group(1)\n",
        "        if (guess := match_numbers.search(r)) is not None else None \\\n",
        "        for r in responses\n",
        "    ]\n",
        "\n",
        "    scores = []\n",
        "    # Print only every few steps\n",
        "    global PRINTED_TIMES\n",
        "    global PRINT_EVERY_STEPS\n",
        "    if PRINTED_TIMES % PRINT_EVERY_STEPS == 0:\n",
        "        print(\n",
        "            '*'*20 + f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\"\n",
        "        )\n",
        "    PRINTED_TIMES += 1\n",
        "\n",
        "    for guess, true_answer in zip(extracted_responses, answer):\n",
        "        if guess is None:\n",
        "            scores.append(-2.5)\n",
        "            continue\n",
        "        # Convert to numbers\n",
        "        try:\n",
        "            true_answer = float(true_answer.strip())\n",
        "            # Remove commas like in 123,456\n",
        "            guess       = float(guess.strip().replace(\",\", \"\"))\n",
        "            scores.append(3.5 if guess == true_answer else -1.5)\n",
        "        except:\n",
        "            scores.append(0)\n",
        "            continue\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgOR3wJ_AyLr"
      },
      "source": [
        "Get the top 90% prompt length so we don't accidentally truncate them!\n",
        "\n",
        "Ie we'll remove the top 10% long prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EgAi4Q5fGE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29144f96-3792-4dda-9279-f52cde91b2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are given a problem.\n",
            "Think about the problem and provide your working out.\n",
            "Place it between <start_working_out> and <end_working_out>.\n",
            "Then, provide your solution between <SOLUTION></SOLUTION><|endoftext|>In triangle $ABC$, $\\sin \\angle A = \\frac{4}{5}$ and $\\angle A < 90^\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\angle BAD = \\angle DAC$ and $\\angle BDC = 90^\\circ$. Suppose that $AD = 1$ and that $\\frac{BD}{CD} = \\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\frac{a\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.<start_working_out>\n",
            "Max Length =  201\n"
          ]
        }
      ],
      "source": [
        "tokenized = dataset.map(\n",
        "    lambda x: {\"tokens\" : tokenizer.apply_chat_template(x[\"prompt\"], add_generation_prompt = True, tokenize = True)},\n",
        "    batched = True,\n",
        ")\n",
        "print(tokenizer.decode(tokenized[0][\"tokens\"]))\n",
        "tokenized = tokenized.map(lambda x: {\"L\" : len(x[\"tokens\"])})\n",
        "\n",
        "import numpy as np\n",
        "maximum_length = int(np.quantile(tokenized[\"L\"], 0.9))\n",
        "print(\"Max Length = \", maximum_length)\n",
        "\n",
        "# Filter only samples smaller than 90% max length\n",
        "dataset = dataset.select(np.where(np.array(tokenized[\"L\"]) <= maximum_length)[0])\n",
        "del tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-IOMhVg-2AM"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptqkXK2D4d6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51eba1a-b026-4064-f771-c52282a01808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 4\n"
          ]
        }
      ],
      "source": [
        "max_prompt_length = maximum_length + 1 # + 1 just in case!\n",
        "max_completion_length = max_seq_length - max_prompt_length\n",
        "\n",
        "from vllm import SamplingParams\n",
        "vllm_sampling_params = SamplingParams(\n",
        "    min_p = 0.1,\n",
        "    top_p = 1.0,\n",
        "    top_k = -1,\n",
        "    seed = 3407,\n",
        "    stop = [tokenizer.eos_token],\n",
        "    include_stop_str_in_output = True,\n",
        ")\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    vllm_sampling_params = vllm_sampling_params,\n",
        "    temperature = 1.0,\n",
        "    learning_rate = 5e-6,\n",
        "    weight_decay = 0.01,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    optim = \"adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 4, # Decrease if out of memory\n",
        "    max_prompt_length = max_prompt_length,\n",
        "    max_completion_length = max_completion_length,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 100,\n",
        "    save_steps = 100,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        "\n",
        "    # For optional training + evaluation\n",
        "    # fp16_full_eval = True,\n",
        "    # per_device_eval_batch_size = 4,\n",
        "    # eval_accumulation_steps = 1,\n",
        "    # eval_strategy = \"steps\",\n",
        "    # eval_steps = 1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Mv8UZO5hz-"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzOuSVCL_GA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87a2378f-c462-4c92-f3e1-b2e1c7981b22"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 12,709 | Num Epochs = 1 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 66,060,288/4,000,000,000 (1.65% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250523_180213-sdp98xxu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/farzam-hejazi-tutor-gal/huggingface/runs/sdp98xxu' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/farzam-hejazi-tutor-gal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/farzam-hejazi-tutor-gal/huggingface' target=\"_blank\">https://wandb.ai/farzam-hejazi-tutor-gal/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/farzam-hejazi-tutor-gal/huggingface/runs/sdp98xxu' target=\"_blank\">https://wandb.ai/farzam-hejazi-tutor-gal/huggingface/runs/sdp98xxu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 32768, 'bos_token_id': 151643, 'eos_token_id': 151643}. If this is not desired, please set these values explicitly.\n",
            "/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py:438: UserWarning: An output with one or more elements was resized since it had shape [1, 4, 2560], which does not match the required output shape [4, 1, 2560]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)\n",
            "  out = torch_matmul(X, W.t(), out = out)\n",
            "/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py:443: UserWarning: An output with one or more elements was resized since it had shape [1, 4, 2560], which does not match the required output shape [4, 1, 2560]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)\n",
            "  out = torch_matmul(X, W, out = out)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************Question:\n",
            "Compute the number of positive integers that divide at least two of the integers in the set $\\{1^1,2^2,3^3,4^4,5^5,6^6,7^7,8^8,9^9,10^{10}\\}$. \n",
            "Answer:\n",
            "22 \n",
            "Response:\n",
            "Okay, let's see. I need to find how many positive integers divide at least two of the numbers in the set {1^1, 2^2, 3^3, ..., 10^10}. Hmm, so first, I should list out all these numbers and maybe factor them into primes to find their divisors. But wait, since we're interested in divisors that appear in at least two numbers, maybe I should look at the prime factors of each number and see which primes are common across different exponents.\n",
            "\n",
            "Let me start by writing out each number in the set and factorizing them:\n",
            "\n",
            "1^1 = 1 (which has no prime factors other than 1, but divisors are 1)\n",
            "2^2 = 4 = 2^2\n",
            "3^3 = 27 = 3^3\n",
            "4^4 = (2^2)^4 = 2^8\n",
            "5^5 = 5^5\n",
            "6^6 = (2*3)^6 = 2^6 * 3^6\n",
            "7^7 = 7^7\n",
            "8^8 = (2^3)^8 = 2^24\n",
            "9^9 = (3^2)^9 = 3^18\n",
            "10^10 = (2*5)^10 = 2^10 * 5^10\n",
            "\n",
            "Now, for each number, the number of divisors is calculated by adding 1 to each exponent in the prime factorization and multiplying them. But for this problem, I need to count all divisors that are common to at least two numbers. So I need to find all divisors that appear in the prime factorization of any two numbers.\n",
            "\n",
            "Let me list the exponents for each prime across all numbers.\n",
            "\n",
            "For prime 2:\n",
            "- 1^1: 0\n",
            "- 2^2: 2\n",
            "- 4^4: 8\n",
            "- 6^6: 6\n",
            "- 8^8: 24\n",
            "- 10^10: 10\n",
            "\n",
            "For prime 3:\n",
            "- 3^3: 3\n",
            "- 6^6: 6\n",
            "- 9^9: 18\n",
            "\n",
            "For prime 5:\n",
            "-5^5:5\n",
            "-10^10:10\n",
            "\n",
            "Other primes like 7 are only in 7^7, and other primes (11, 13, ...) don't appear at all.\n",
            "\n",
            "So, let's consider each prime separately. For each prime p, I need to determine how many distinct exponents (e) it appears with in the numbers. The number of divisors for that prime is e + 1, but since we want divisors that divide at least two numbers, for each prime, we need to consider the exponents that are present in at least two numbers. Then, the total number of divisors that divide at least two numbers would be the product over all primes of (sum over exponents of p in at least two numbers (e + 1)).\n",
            "\n",
            "Wait, so maybe after sorting the exponents for each prime, I can find the count of exponents that appear more than once for each prime.\n",
            "\n",
            "Let me work through each prime:\n",
            "\n",
            "Prime 2: exponents are 0, 2, 6, 8, 10, 24.\n",
            "But 0 is for 1^1, so 1^1 doesn't contribute to prime 2. So we ignore the 0. The exponents are 2,6,8,10,24. How many elements have the same exponent? Let's check: 2 appears once, 6 once, 8 once, 10 once, 24 once. None of these exponents repeat. Therefore, for prime 2, there's no exponents that appear in more than one number except 0, which we already excluded.\n",
            "\n",
            "Prime 3: exponents are 3,6,18. So 3,6,18. How many elements have same exponents: 3 appears once, 6 once, 18 once. Again, no repeats.\n",
            "\n",
            "Prime 5: exponents are 5,10. So 5 and 10. No repeats.\n",
            "\n",
            "Prime 7: exponent 7 in 7^7. Only one exponent, so no repeats.\n",
            "\n",
            "Primes like 11,13: exponents 1, so only one exponent each.\n",
            "\n",
            "Therefore, for each prime, none of the exponents appear in more than one number. But 1^1's divisor is 1, which is a divisor of every number. So the number 1 is counted as a divisor in all 10 numbers. So 1 contributes 10 to the total count. Then, for primes 2,3,5,7 with their exponents, since they each have exponents with no repeats, each prime's divisors only appear in one number, so they don't contribute any to the count. So the only divisors that appear in at least two numbers are the 1s.\n",
            "\n",
            "But wait, that can't be right. Because even if a prime's exponent is unique, but any divisor of that number is a product of primes. But in our case, since the exponents for each prime are unique across numbers, then any divisor of a number that uses a prime's exponent will only be shared with that number's exponent. For example, for prime 2, exponents 2,6,8,10,24, the divisors would be 2^a where a <= exponent. But since each exponent is unique, then divisors 2^a for each exponent are unique. Therefore, if a divisor is common to two numbers, it would need to be a divisor of both. However, in this case, each exponent for prime 2 is unique, so each 2^a is unique. Therefore, no two numbers share a divisor other than 1.\n",
            "\n",
            "Therefore, the only divisors that are common to at least two numbers are the 1s. Therefore, the total number is 10 (since each number has 1 as a divisor, and 1 divides all 10 numbers). Wait, but the problem says \"at least two of the integers\". Wait, so 1 divides all 10 numbers, so 1 is counted in every number. Therefore, the total would be 10.\n",
            "\n",
            "But wait, is that correct? Let me check again.\n",
            "\n",
            "The problem is to count the number of positive integers that divide at least two numbers. So if 1 divides all numbers, then 1 is counted 10 times. But 1 is the only such divisor because all others are unique for each number.\n",
            "\n",
            "But wait, let's take the example. Let's see. For instance, take prime 2 with exponents 2,6,8,10,24. Each of these exponents corresponds to a number. So the divisors of 4^4 (2^8) are 2^0 to 2^8, which are 9 numbers. But 2^8 is unique. Similarly for other numbers. So each divisor of each number is unique. So no two divisors can be shared between numbers.\n",
            "\n",
            "Therefore, indeed, the only divisors common to at least two numbers is 1. Hence, the answer is 10.\n",
            "\n",
            "But wait, this seems too straightforward. However, the problem is that exponents for each prime are unique, hence each prime's divisors are unique across numbers. Therefore, only 1 can be divisor of multiple numbers. Therefore, 1 divides all numbers, so 1 is counted 10 times. So the answer is 10.\n",
            "\n",
            "But let's check if there's any other divisors. For example, 2. The number 2^2 is 4, and its divisors are 1 and 2. However, none of the other numbers have 2 as a divisor except maybe 8^8, but 8^8 is 2^24, and 4 is 2^2. So 2 is a divisor of 4^4 and 8^8, right? Wait, 4^4 is 2^8, and 8^8 is 2^24. So 2 is a divisor of both. However, 2 is only present as a divisor in 4^4 and 8^8. So 2 is a divisor of two numbers, so it counts as a divisor. Therefore, 2 is counted once. Then 3: if 3 is a divisor of 3^3 and 6^6, but 3^3's divisors include 1 and 3^k where k=0 to3, but 6^6 is 2^6*3^6. So 3^6 is in 6^6, but 3^3 is in 3^3. However, 3^3 is not a divisor of 6^6 because 6^6 = 2^6*3^6, so the highest power of 3 is 6. Therefore, 3^3 is a divisor of 3^3 but not of 6^6. Wait, no. Wait, 3^3 is a divisor of 3^3, but does it divide 6^6? Let's think: 6^6 / 3^3 = (2*3)^6 / 3^3 = 2^6 * 3^6 / 3^3 = 2^6 * 3^3, which is an integer. So 3^3 divides 6^6. So 3^3 is a divisor of both 3^3 and 6^6. Therefore, 3^3 is a divisor counted twice. Wait, so that's a different case.\n",
            "\n",
            "Wait, so 3^3 (which is 27) divides both 3^3 (which is 27) and 6^6 (which is 46656). So 27 is a divisor of both, so it counts as a divisor. So 27 is another divisor. Then primes 3 and 5 also have exponents that can overlap. So let's check those.\n",
            "\n",
            "For prime 3: exponents 3 (3^3), 6 (6^6), 18 (9^9). So 3^3, 3^6, 3^18. The divisor 3^3 is present in both 3^3 and 6^6. Then 3^6 is in 6^6 and 3^6? Wait, 3^6 is in 6^6, but where else? Let's see. 6^6 is 2^6*3^6. So the exponents of primes are 2 and 3. The exponent for 3 is 6. So 3^6 is a divisor. Similarly, 9^9 is 3^18. So 3^18 is a divisor there. So 3^6 is in both 6^6 and (where?) 3^3? 3^3 is 3^3. So, 3^3 divides both 3^3 and 6^6. Then 3^6 divides both 6^6 and where else? 9^9. Then 3^9 divides 9^9. So 3^6 divides 6^6 and 9^9? Yes, because 6^6 is 3^6*2^6 and 9^9 is 3^18. So 3^6 divides both 6^6 and 9^9. Similarly, 3^9 divides 9^9, so 3^9 divides 9^9. However, 3^9 does not divide 6^6 because 6^6 is 3^6*2^6, so the exponent of 3 is 6. Therefore, 3^9 does not divide 6^6. Therefore, the only exponent of 3 that appears in both 6^6 and 9^9 is 6. Similarly, 3^3 appears in 3^3 and 6^6. So, the exponents 3 and 6 for prime 3 are present in 6^6 and 9^9, so these two exponents correspond to divisors 3^3 and 3^6 which divide both 3^3 and 6^6 as well as 9^9. Similarly for prime 5. Exponents 5 and 10 for 5^5 and 10^10. So 5^5 and 5^10. The divisors of 5^5 are 5^0 to 5^5. The divisors of 10^10 include 5^0 to 5^10. Therefore, 5^5 divides both 5^5 and 10^10, and 5^10 divides 10^10. Therefore, the two exponents 5 and 10 for prime 5 also contribute to divisors that are common. Therefore, divisors 5^5 and 5^10 are counted.\n",
            "\n",
            "Therefore, primes 3 and 5 each contribute two divisors: 3^3 and 3^6 for prime 3, and 5^5 and 5^10 for prime 5. Each of these divisors is counted in two numbers. For prime 2, none, as each exponent is unique. Prime 1 does not contribute any divisors beyond 1.\n",
            "\n",
            "Therefore, the total number of positive integers (excluding 1) is 2 (from prime 3) + 2 (from prime 5) = 4. Then adding the 1s, which are 10, so total is 14.\n",
            "\n",
            "Wait, but let's verify:\n",
            "\n",
            "Divisors from prime 3: 1, 3, 9, 27, 81, 243, 729, 2187, 6561, 19683, 59049 (but these are up to 3^6). These are divisors of 6^6 and 9^9. Similarly, divisors of 5^5: 1,5,25,125,625,3125,15625,78125,390625,1953125. Divisors of 10^10: 1,5,25,125,625,3125,15625,78125,390625,1953125,9765625,48828125,244140625,1220703125,6103515625. So the exponents 5 and 10 for prime 5 contribute 5^5 (which is divisor of both) and 5^10. Therefore, 5^5 and 5^10 contribute two divisors. For prime 3, 3^3 and 3^6 contribute two divisors each. Therefore, the total divisors that divide at least two numbers are:\n",
            "\n",
            "1 (counted 10 times)\n",
            "2 (counts as divisor of 4^4 and 8^8)\n",
            "3^3 (divides 3^3 and 6^6)\n",
            "3^6 (divides 6^6 and 9^9)\n",
            "5^5 (divides 5^5 and 10^10)\n",
            "5^10 (divides 10^10)\n",
            "\n",
            "Therefore, total divisors: 10 (from 1) + 5 (from 2,3^3,3^6,5^5,5^10) = 15. Hold on, 2 is 1, 3^3 is 1, 3^6 is 1, 5^5 is 1, 5^10 is 1. So total 1 +1 +1 +1 +1 =5, plus 10 from the 1s? Wait, no. Wait, 1 is included in all divisors. So the count of divisors is 10 (from the 1s) plus how many divisors are at least two, so 2 (appears in 4^4 and 8^8), 3^3 (appears in 3^3 and 6^6), 3^6 (appears in 6^6 and 9^9), 5^5 (appears in 5^5 and 10^10), 5^10 (appears in 10^10). So 10 (from all numbers' 1) + 5 (from 2, 3^3, 3^6, 5^5,5^10). So total 15. Therefore, the answer is 15. Wait, but let me check again. Wait, 2 is a single divisor (as a number), 3^3 is one, 3^6 is another, 5^5 is another, 5^10 is another. So that's 5 divisors besides 1. So total 10 +5=15.\n",
            "\n",
            "Wait, but 1 is counted 10 times, and then each of the 5 (as numbers 2,3^3,3^6,5^5,5^10) is counted once. So 10 +5=15. Therefore, the answer is 15. So, 15 is the total number of divisors.\n",
            "\n",
            "But let me confirm the divisors:\n",
            "\n",
            "From prime 3: 3^0 (1), 3^1 (3), 3^2 (9), 3^3 (27), 3^4 (81), 3^5 \n",
            "Extracted:\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  8/100 36:06 < 9:13:32, 0.00 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / match_format_exactly</th>\n",
              "      <th>rewards / match_format_approximately</th>\n",
              "      <th>rewards / check_answer</th>\n",
              "      <th>rewards / check_numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.006500</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3894.000000</td>\n",
              "      <td>0.162891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.077800</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3894.000000</td>\n",
              "      <td>1.944303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.043300</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3894.000000</td>\n",
              "      <td>1.083140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.084500</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3894.000000</td>\n",
              "      <td>2.112347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.021800</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3894.000000</td>\n",
              "      <td>0.543772</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.186700</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3894.000000</td>\n",
              "      <td>4.668663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py:438: UserWarning: An output with one or more elements was resized since it had shape [1, 4, 2560], which does not match the required output shape [4, 1, 2560]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)\n",
            "  out = torch_matmul(X, W.t(), out = out)\n",
            "/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py:443: UserWarning: An output with one or more elements was resized since it had shape [1, 4, 2560], which does not match the required output shape [4, 1, 2560]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)\n",
            "  out = torch_matmul(X, W, out = out)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "********************Question:\n",
            "The sum of $\\lfloor x \\rfloor$ for all real numbers $x$ satisfying the equation $16 + 15x + 15x^2 = \\lfloor x \\rfloor^3$ is: \n",
            "Answer:\n",
            "33 \n",
            "Response:\n",
            "A</////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////Y</////////////////////////////////////////////////////A<////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////A</////A<////////////////////////////////////////////////////////////////////A<////////////////////////////////A<A<////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////A</////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////A</////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////A<////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////A</////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////A///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////A/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// \n",
            "Extracted:\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# For optional training + evaluation\n",
        "# new_dataset = dataset.train_test_split(test_size = 0.01)\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        match_format_exactly,\n",
        "        match_format_approximately,\n",
        "        check_answer,\n",
        "        check_numbers,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        "\n",
        "    # For optional training + evaluation\n",
        "    # train_dataset = new_dataset[\"train\"],\n",
        "    # eval_dataset = new_dataset[\"test\"],\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlaUdxC_VHpz"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtcz_lpbVC92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "1cc24ae1ea2e498f8ce1b7afb016f946",
            "3f99af7066114110bc28d113ee32072d",
            "fa6ed0d48fd04726b9a6bc92b5ec3708",
            "2aee8e461c3144c382532649cc067f61",
            "41ff4ea73396420f952b396560249270",
            "74afa76a26f245519932d02b8042e5ab",
            "c9a4ebf0f16d499a917034f45ec7050f",
            "aee30c91cc634ee2b8dd9ed9238c8377",
            "6e482123e4aa4a3195a5b5a5d4289a20",
            "13824ab11776462199dc487e3dd9f33f",
            "e82075463a424e5e8dc62dee8ff2686e"
          ]
        },
        "outputId": "4690e0ea-74ec-448e-94ac-1ec0d8240e5c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc24ae1ea2e498f8ce1b7afb016f946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" - Answers\\nMath and Arithmetic\\nGeometry\\nNumbers\\nSquare Roots\\nWhat is the sqrt of 101?\\nWiki User\\n∙ 2011-05-12 02:55:35\\nStudy now\\nBest Answer\\nCopy\\n101 squared is equal to 10201, which is itself a perfectly good\\nnumber\\nWiki User\\n∙ 2011-05-12 02:55:35\\nThis answer is:\\n🙏\\n0\\n🤨\\n0\\n😮\\n0\\nStudy guides\\nAlgebra\\n20 cards\\nA polynomial of degree zero is a constant term\\nThe grouping method of factoring can still be used when only some of the terms share a common factor A True B False\\nA number a power of a variable or a product of the two is a monomial while a polynomial is the of monomials\\n3.71 (14)\\n☆★☆★☆★☆★☆★\\n208 Reviews\\nHow do you square a number on scientific calculator?\\nWhen you want to take the square of 126.45, for example, you\\nwould press the numbers, 1 2 6 . 4 5 = x2. If you are using the\\ntraditional form of calculator, which may have a square root sign\\non it, the square roots would be found by pressing the numbers 1 2\\n6 . 4 5 = &radic;\\nHow do I find the square root of 82?\\nThe square root of 82 is approximately 9.0554. This can be\\ncalculated using a calculator or sqrt function and plugging in 82.\\nThe sqrt function and calculator can be found in all calculators.\\nWhat is Sqrt 45 over 325?\\nsqrt (45)/325 = sqrt (4*9*5)/(325)\\n= sqrt(9)*sqrt(4)*sqrt(5)/(sqrt(13)*sqrt(25))\\n= 3*2*sqrt(5)/(sqrt(13)*5)\\n= 6*sqrt(5)/5*sqrt(13)\\n= 6/sqrt(65)\\n= 6/sqrt(5*13)\\nThis can't be simplified further\\nThe decimal value is 0.7483...\\nWhat is the Sqrt of 196?\\nThe sqrt of 196 is 14 because it is 14 x 14.\\nWhat is the Sqrt of 2048?\\n64 is.\\nWhat is the Sqrt of 652?\\n25.53428817036236\\nWhat is the Sqrt of 7056?\\nIt is 84.\\nWhat is the Sqrt of 533?\\n23.09097915260612\\nWhat is the Sqrt of 5184?\\n72.\\nWhat is the Sqrt of 0.45?\\nit id not possible to calculate sqrt 0.45 because the problem\\nsits at 19.68193943504027 but i am not able to calculate it\\nWhat the Sqrt of 8?\\n2.828427125\\nWhat is the Sqrt of 162?\\n12.72792206135785\\nWhat is the Sqrt of 64416?\\n253.80435080562047\\nWhat is the Sqrt of 50?\\n5*sqrt(2)= 7.07106781186\\nWhat is the Sqrt of 2209?\\nThe 2 square times 25 square\\nWhat is the Sqrt of 1764?\\nThe 42 square\\nWhat is sqrt of 150?\\nIt is approximately +12.25\\nWhat is the Sqrt of 82?\\nsqrt(82) = &radic;82. But you can only put it in simplest radical form if it is a perfect square so for 82 it is not because a perfect square is a number which is the product of 2 identical numbers eg 81=9 * 9\\nWhat is the Sqrt of 64?\\nThe sqrt of 64 is 2 * 2 * 2 * 2 = 16\\nWhat is the Sqrt of 7?\\nSqrt is 91\\nWhat is the Sqrt of 16?\\nThe sqrt of sixteen = 4\\nWhat is the Sqrt of 11\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "text = \"What is the sqrt of 101?\"\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 1.0,\n",
        "    top_k = 50,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Colxz9TAVMsi"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-BcuB1VLIv"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4LMOBl8boGX"
      },
      "source": [
        "Verify LoRA is actually trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SfdI-ERbpiw"
      },
      "outputs": [],
      "source": [
        "from safetensors import safe_open\n",
        "\n",
        "tensors = {}\n",
        "with safe_open(\"grpo_saved_lora/adapter_model.safetensors\", framework = \"pt\") as f:\n",
        "    # Verify both A and B are non zero\n",
        "    for key in f.keys():\n",
        "        tensor = f.get_tensor(key)\n",
        "        n_zeros = (tensor == 0).sum() / tensor.numel()\n",
        "        assert(n_zeros.item() != tensor.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwpbwnDBVRLg"
      },
      "source": [
        "Now we load the LoRA and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf_OY5WMVOxF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716,
          "referenced_widgets": [
            "4e5ebf7203b2467abdd0b871d6b72f7a",
            "f2fd49b789d3418292c1bcd1439e2e84",
            "11f935907b9e469e8167c7669764ae4c",
            "81d28dde142049519cd27f87c68c92fa",
            "c73269d5f6134c539249d28e7809a003",
            "b9f877c8eb5c4f78821d40f27a867f09",
            "493acc3b55f441219300802810be7004",
            "eccb880d39da499db25b740262916944",
            "9a51e7c117924754acddc2d2750d3ac0",
            "85cf8527998d49c18d89f8d82271c534",
            "fe778d62c7f34683810ad613114ae4c1"
          ]
        },
        "outputId": "0336f5d4-5446-4a2c-9c5c-30815980d7b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e5ebf7203b2467abdd0b871d6b72f7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, so I need to find the square root of 101. Hmm, I remember that square roots are about finding a number that, when multiplied by itself, gives the original number. But 101 isn't a perfect square, right? Let me think. The squares around 101 would be 100 (which is 10 squared) and 121 (which is 11 squared). So the square root of 101 is somewhere between 10 and 11. \\n\\nBut the problem is asking for the square root, which might be an irrational number. So maybe it's a decimal? Let me try to estimate. I need to find the number that's closer to 10.5. Let me test 10.05. If I square that, it's (10 + 0.05)*(10 + 0.05) = 100 + 0.05*10 + 0.05*10 + 0.05*0.05 = 100 + 0.5 + 0.5 + 0.0025 = 101.0025. That's very close to 101. So maybe the square root is 10.05 plus or minus a little bit. \\n\\nBut wait, maybe there's a better way. Since 10.05 squared is 101.0025, which is slightly above 101, the actual square root should be slightly less than 10.05. Let me try 10.04. Squaring 10.04: (10 + 0.04)*(10 + 0.04) = 100 + 0.4 + 0.4 + 0.0016 = 100.8016. That's closer, but still above 101. So maybe 10.045? Let me compute that. \\n\\n10.045 squared would be (10 + 0.045)^2 = 100 + 0.045*10 + 0.045*10 + 0.045*0.045 = 100 + 0.45 + 0.45 + 0.002025 = 100.892025. Still above. Hmm, maybe 10.03? \\n\\n10.03 squared is (10 + 0.03)* (10 + 0.03) = 100 + 0.3 + 0.3 + 0.0009 = 100.6009. That's below 101. So between 10.03 and 10.045. Let me try 10.042. \\n\\n10.042 squared is about 100 + 0.42 + 0.42 + 0.001764 = 100.841764. Still above 101. Let's try 10.04. Wait, 10.04 squared is 100.8016, which is below 101. So the square root is between 10.04 and 10.042. \\n\\nAlternatively, maybe I can use the formula for the square root more precisely. Let's assume that the square root is 10.05 - x. Then (10.05 - x)^2 = 101. Expanding, that's 101.0025 - 20.1x + x^2 = 101. So 20.1x - x^2 = 0.0025. Since x is small, x^2 is negligible. So 20.1x ≈ 0.0025. Then x ≈ 0.0025 / 20.1 ≈ 0.000124. So 10.05 - 0.000124 ≈ 10.049876. Let me check this. \\n\\n10.049876 squared: approximately 100.9999... which is very close to 101. This makes sense. So the square root of 101 is approximately 10.0498756211. \\n\\nWait, but maybe there's a more efficient method. Like using the Newton-Raphson method for finding roots. Let me recall. The formula is x_{n+1} = x_n - f(x_n)/f'(x_n). For square root of a, the function is f(x) = x^2 - a, so f'(x) = 2x. So starting with an initial guess, say x0 = 10. Then x1 = 10 - (100 - 101)/(2*10) = 10 - (-1)/20 = 10 + 0.05 = 10.05. Then x2 = 10.05 - (10.05^2 - 101)/(2*10.05). \\n\\nCompute 10.05^2: 100.0025. So (10.05^2 - 101) = 10.05^2 - 101 = -0.9975. Then x2 = 10.05 - (-0.9975)/20.1 ≈ 10.05 + 0.049627 = 10.099627. Wait, that seems higher than the previous approximation. Maybe I made a mistake in the calculation. Let me recalculate.\\n\\nOriginal equation x_{n+1} = x_n - (x_n^2 - a)/(2x_n). So for x0 = 10, x1 = 10 - (100 - 101)/(20) = 10 + 0.05 = 10.05. Then for x1=10.05, x2 = 10.05 - (10.05^2 - 101)/(2*10.05). \\n\\n10.05^2 = 101.0025. So numerator is 101.0025 - 101 = 0.0025. Denominator is 2*10.05 = 20.1. So x2 = 10.05 - 0.0025/20.1 ≈ 10.05 - 0.000124 ≈ 10.049876. Ok, that matches the earlier approximation. So the square root of 101 is approximately 10.0498756211. \\n\\nBut to present it more neatly, maybe up to a certain decimal place. Since the problem didn't specify, perhaps the exact answer is left as √101, but if we need an approximation, it's 10.049987551. But after checking, it's approximately 10.0498756211. Therefore, the square root of 101 is √101, which is approximately 10.0498756211.\\nTo find the square root of 101, we can use the fact that it lies between the perfect squares of 10 and 11. Let's start by noting that:\\n\\n\\\\[ 10^2 = 100 \\\\]\\n\\\\[ 11^2 = 121 \\\\]\\n\\nThus, \\\\(\\\\sqrt{101}\\\\) is between 10 and 11. To get a more precise estimate, we can use the Newton-Raphson method, which is an iterative method for finding roots of equations. We start with an initial guess \\\\(x_0 = 10\\\\).\\n\\nThe Newton-Raphson formula for finding the square root of \\\\(a\\\\) is given by:\\n\\n\\\\[ x_{n+1} = x_n - \\\\frac{x_n^2 - a}{2x_n} \\\\]\\n\\nLet's perform the iterations:\\n\\n1. **First iteration**:\\n   \\\\[\\n   x_0 = 10\\n   \\\\]\\n   \\\\[\\n   x_1 = 10 - \\\\frac{10^2 - 101}{2 \\\\cdot 10} = 10 - \\\\frac{100 - 101}{20} = 10 + \\\\frac{1}{20} =\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\",   \"content\": \"What is the sqrt of 101?\"},\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    tokenize = False,\n",
        ")\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 1.0,\n",
        "    top_k = 50,\n",
        "    max_tokens = 2048,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aDgFfhFYIAS"
      },
      "source": [
        "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NUEmHFSYNTp"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjXGTkp7YNtB"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WMb3k_YPt8"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEjW-WuYQIm"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V15Yhj1V9lwG"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e32cde8bae04944acb9b81d72083d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c310891371442e7ace9bb2cb427f157",
              "IPY_MODEL_e79bc585dceb4cf78d07b006517de7da",
              "IPY_MODEL_acab127a93654604ae5c7b2b3241e262"
            ],
            "layout": "IPY_MODEL_12630f33d40541b6bcb63b86be4b340c"
          }
        },
        "8c310891371442e7ace9bb2cb427f157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd27e26dd6c4f5a80d4ee674e3a1941",
            "placeholder": "​",
            "style": "IPY_MODEL_13ac50082b6744a2b70b2bf785b5299c",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
          }
        },
        "e79bc585dceb4cf78d07b006517de7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2bb8a2af8ba451fa113d77556080d3e",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a4ffe2fa4e04945b816752992077a79",
            "value": 59
          }
        },
        "acab127a93654604ae5c7b2b3241e262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d796eb8672674433ba1d6378d7140623",
            "placeholder": "​",
            "style": "IPY_MODEL_44e07fc58e3e44fb9223e7cec91847d6",
            "value": " 59/59 [00:01&lt;00:00, 47.67 examples/s]"
          }
        },
        "12630f33d40541b6bcb63b86be4b340c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd27e26dd6c4f5a80d4ee674e3a1941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ac50082b6744a2b70b2bf785b5299c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2bb8a2af8ba451fa113d77556080d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4ffe2fa4e04945b816752992077a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d796eb8672674433ba1d6378d7140623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e07fc58e3e44fb9223e7cec91847d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cc24ae1ea2e498f8ce1b7afb016f946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f99af7066114110bc28d113ee32072d",
              "IPY_MODEL_fa6ed0d48fd04726b9a6bc92b5ec3708",
              "IPY_MODEL_2aee8e461c3144c382532649cc067f61"
            ],
            "layout": "IPY_MODEL_41ff4ea73396420f952b396560249270"
          }
        },
        "3f99af7066114110bc28d113ee32072d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74afa76a26f245519932d02b8042e5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c9a4ebf0f16d499a917034f45ec7050f",
            "value": "Processed prompts: 100%"
          }
        },
        "fa6ed0d48fd04726b9a6bc92b5ec3708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee30c91cc634ee2b8dd9ed9238c8377",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e482123e4aa4a3195a5b5a5d4289a20",
            "value": 1
          }
        },
        "2aee8e461c3144c382532649cc067f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13824ab11776462199dc487e3dd9f33f",
            "placeholder": "​",
            "style": "IPY_MODEL_e82075463a424e5e8dc62dee8ff2686e",
            "value": " 1/1 [00:41&lt;00:00, 41.39s/it, est. speed input: 0.24 toks/s, output: 24.74 toks/s]"
          }
        },
        "41ff4ea73396420f952b396560249270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "74afa76a26f245519932d02b8042e5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a4ebf0f16d499a917034f45ec7050f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aee30c91cc634ee2b8dd9ed9238c8377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e482123e4aa4a3195a5b5a5d4289a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13824ab11776462199dc487e3dd9f33f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82075463a424e5e8dc62dee8ff2686e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e5ebf7203b2467abdd0b871d6b72f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2fd49b789d3418292c1bcd1439e2e84",
              "IPY_MODEL_11f935907b9e469e8167c7669764ae4c",
              "IPY_MODEL_81d28dde142049519cd27f87c68c92fa"
            ],
            "layout": "IPY_MODEL_c73269d5f6134c539249d28e7809a003"
          }
        },
        "f2fd49b789d3418292c1bcd1439e2e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f877c8eb5c4f78821d40f27a867f09",
            "placeholder": "​",
            "style": "IPY_MODEL_493acc3b55f441219300802810be7004",
            "value": "Processed prompts: 100%"
          }
        },
        "11f935907b9e469e8167c7669764ae4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eccb880d39da499db25b740262916944",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a51e7c117924754acddc2d2750d3ac0",
            "value": 1
          }
        },
        "81d28dde142049519cd27f87c68c92fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85cf8527998d49c18d89f8d82271c534",
            "placeholder": "​",
            "style": "IPY_MODEL_fe778d62c7f34683810ad613114ae4c1",
            "value": " 1/1 [01:33&lt;00:00, 93.24s/it, est. speed input: 0.62 toks/s, output: 21.35 toks/s]"
          }
        },
        "c73269d5f6134c539249d28e7809a003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b9f877c8eb5c4f78821d40f27a867f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "493acc3b55f441219300802810be7004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eccb880d39da499db25b740262916944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a51e7c117924754acddc2d2750d3ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85cf8527998d49c18d89f8d82271c534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe778d62c7f34683810ad613114ae4c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}